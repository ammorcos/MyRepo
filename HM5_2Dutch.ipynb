{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 5: Build a seq2seq model for machine translation.\n",
    "\n",
    "### Name: [Amir Morcos]\n",
    "\n",
    "### Task: Translate English to [Dutch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read and run my code.\n",
    "2. Complete the code in Section 1.1 and Section 4.2.\n",
    "\n",
    "    * Translation **English** to **German** is not acceptable!!! Try another pair of languages.\n",
    "    \n",
    "3. **Make improvements.** Directly modify the code in Section 3. Do at least one of the two. By doing both correctly, you will get up to 1 bonus score to the total.\n",
    "\n",
    "    * Bi-LSTM instead of LSTM.\n",
    "        \n",
    "    * Attention. (You are allowed to use existing code.)\n",
    "    \n",
    "4. Evaluate the translation using the BLEU score. \n",
    "\n",
    "    * Optional. Up to 1 bonus scores to the total.\n",
    "    \n",
    "5. Convert the notebook to .HTML file. \n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "\n",
    "6. Put the .HTML file in your Google Drive, Dropbox, or Github repo.  (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "7. Submit the link to the HTML file to Canvas.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hint: \n",
    "\n",
    "To implement ```Bi-LSTM```, you will need the following code to build the encoder. Do NOT use Bi-LSTM for the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.layers import Bidirectional, Concatenate\n",
    "\n",
    "#encoder_bilstm = Bidirectional(LSTM(latent_dim, return_state=True, \n",
    "#                                  dropout=0.5, name='encoder_lstm'))\n",
    "#_, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_inputs)\n",
    "\n",
    "#state_h = Concatenate()([forward_h, backward_h])\n",
    "#state_c = Concatenate()([forward_c, backward_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "1. Download data (e.g., \"deu-eng.zip\") from http://www.manythings.org/anki/\n",
    "2. Unzip the .ZIP file.\n",
    "3. Put the .TXT file (e.g., \"deu.txt\") in the directory \"./Data/\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load and clean text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from unicodedata import normalize\n",
    "import numpy\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "\n",
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in  lines]\n",
    "    return pairs\n",
    "\n",
    "def clean_data(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for pair in lines:\n",
    "        clean_pair = list()\n",
    "        for line in pair:\n",
    "            # normalize unicode characters\n",
    "            line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "            line = line.decode('UTF-8')\n",
    "            # tokenize on white space\n",
    "            line = line.split()\n",
    "            # convert to lowercase\n",
    "            line = [word.lower() for word in line]\n",
    "            # remove punctuation from each token\n",
    "            line = [word.translate(table) for word in line]\n",
    "            # remove non-printable chars form each token\n",
    "            line = [re_print.sub('', w) for w in line]\n",
    "            # remove tokens with numbers in them\n",
    "            line = [word for word in line if word.isalpha()]\n",
    "            # store as string\n",
    "            clean_pair.append(' '.join(line))\n",
    "        cleaned.append(clean_pair)\n",
    "    return numpy.array(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill the following blanks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g., filename = 'Data/deu.txt'\n",
    "filename = 'Data/nld.txt'\n",
    "\n",
    "# e.g., n_train = 20000\n",
    "\n",
    "n_train = 35000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "TestSize = 100\n",
    "doc = load_doc(filename)\n",
    "\n",
    "# split into Language1-Language2 pairs\n",
    "pairs = to_pairs(doc)\n",
    "rand_indices = numpy.random.permutation(n_train+TestSize)\n",
    "\n",
    "\n",
    "# clean sentences\n",
    "clean_pairs = clean_data(pairs)[rand_indices[0:n_train], :]\n",
    "Test_pairs = clean_data(pairs)[rand_indices[n_train:n_train+TestSize], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[im a girl] => [ik ben een meisje]\n",
      "[the birds wing was broken] => [de vogel had een gebroken vleugel]\n",
      "[turtles hibernate] => [schildpadden overwinteren]\n",
      "[you stay where you are tom] => [blijf waar je bent tom]\n",
      "[he worked hard] => [hij heeft hard gewerkt]\n",
      "[tom lived in australia] => [tom woonde in australie]\n",
      "[tom cant help you now] => [tom kan u nu niet helpen]\n",
      "[that will cost thirty euros] => [dat wordt dan dertig euro]\n",
      "[see you soon] => [tot weerziens]\n",
      "[im studying french] => [ik ben frans aan het studeren]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3000, 3010):\n",
    "    print('[' + clean_pairs[i, 0] + '] => [' + clean_pairs[i, 1] + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of input_texts:  (30000,)\n",
      "Length of target_texts: (30000,)\n"
     ]
    }
   ],
   "source": [
    "input_texts = clean_pairs[:, 0]\n",
    "target_texts = ['\\t' + text + '\\n' for text in clean_pairs[:, 1]]\n",
    "\n",
    "print('Length of input_texts:  ' + str(input_texts.shape))\n",
    "print('Length of target_texts: ' + str(input_texts.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length of input  sentences: 29\n",
      "max length of target sentences: 58\n"
     ]
    }
   ],
   "source": [
    "max_encoder_seq_length = max(len(line) for line in input_texts)\n",
    "max_decoder_seq_length = max(len(line) for line in target_texts)\n",
    "\n",
    "print('max length of input  sentences: %d' % (max_encoder_seq_length))\n",
    "print('max length of target sentences: %d' % (max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** To this end, you have two lists of sentences: input_texts and target_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text processing\n",
    "\n",
    "### 2.1. Convert texts to sequences\n",
    "\n",
    "- Input: A list of $n$ sentences (with max length $t$).\n",
    "- It is represented by a $n\\times t$ matrix after the tokenization and zero-padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of encoder_input_seq: (30000, 29)\n",
      "shape of input_token_index: 27\n",
      "shape of decoder_input_seq: (30000, 58)\n",
      "shape of target_token_index: 29\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# encode and pad sequences\n",
    "def text2sequences(max_len, lines):\n",
    "    tokenizer = Tokenizer(char_level=True, filters='')\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    seqs = tokenizer.texts_to_sequences(lines)\n",
    "    seqs_pad = pad_sequences(seqs, maxlen=max_len, padding='post')\n",
    "    return seqs_pad, tokenizer.word_index\n",
    "\n",
    "\n",
    "encoder_input_seq, input_token_index = text2sequences(max_encoder_seq_length, \n",
    "                                                      input_texts)\n",
    "decoder_input_seq, target_token_index = text2sequences(max_decoder_seq_length, \n",
    "                                                       target_texts)\n",
    "\n",
    "print('shape of encoder_input_seq: ' + str(encoder_input_seq.shape))\n",
    "print('shape of input_token_index: ' + str(len(input_token_index)))\n",
    "print('shape of decoder_input_seq: ' + str(decoder_input_seq.shape))\n",
    "print('shape of target_token_index: ' + str(len(target_token_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_encoder_tokens: 28\n",
      "num_decoder_tokens: 30\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens = len(input_token_index) + 1\n",
    "num_decoder_tokens = len(target_token_index) + 1\n",
    "\n",
    "print('num_encoder_tokens: ' + str(num_encoder_tokens))\n",
    "print('num_decoder_tokens: ' + str(num_decoder_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, 'e': 2, 'o': 3, 't': 4, 'i': 5, 'a': 6, 's': 7, 'n': 8, 'h': 9, 'r': 10, 'l': 11, 'd': 12, 'y': 13, 'm': 14, 'u': 15, 'w': 16, 'c': 17, 'g': 18, 'p': 19, 'k': 20, 'f': 21, 'b': 22, 'v': 23, 'j': 24, 'x': 25, 'z': 26, 'q': 27}\n"
     ]
    }
   ],
   "source": [
    "print(input_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, 'e': 2, 'n': 3, 'i': 4, 't': 5, 'a': 6, 'o': 7, '\\t': 8, '\\n': 9, 'r': 10, 'd': 11, 's': 12, 'k': 13, 'l': 14, 'h': 15, 'm': 16, 'g': 17, 'j': 18, 'u': 19, 'w': 20, 'b': 21, 'v': 22, 'z': 23, 'p': 24, 'f': 25, 'c': 26, 'y': 27, 'x': 28, 'q': 29}\n"
     ]
    }
   ],
   "source": [
    "print(target_token_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** To this end, the input language and target language texts are converted to 2 matrices. \n",
    "\n",
    "- Their number of rows are both n_train.\n",
    "- Their number of columns are respective max_encoder_seq_length and max_decoder_seq_length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The followings print a sentence and its representation as a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ter is telefoon voor je\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  2, 10,  1,  4, 12,  1,  5,  2, 14,  2, 25,  7,  7,  3,  1, 22,\n",
       "        7,  7, 10,  1, 18,  2,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_seq[100, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. One-hot encode\n",
    "\n",
    "- Input: A list of $n$ sentences (with max length $t$).\n",
    "- It is represented by a $n\\times t$ matrix after the tokenization and zero-padding.\n",
    "- It is represented by a $n\\times t \\times v$ tensor ($t$ is the number of unique chars) after the one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 29, 28)\n",
      "(30000, 58, 30)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# one hot encode target sequence\n",
    "def onehot_encode(sequences, max_len, vocab_size):\n",
    "    n = len(sequences)\n",
    "    data = numpy.zeros((n, max_len, vocab_size))\n",
    "    for i in range(n):\n",
    "        data[i, :, :] = to_categorical(sequences[i], num_classes=vocab_size)\n",
    "    return data\n",
    "\n",
    "encoder_input_data = onehot_encode(encoder_input_seq, max_encoder_seq_length, num_encoder_tokens)\n",
    "decoder_input_data = onehot_encode(decoder_input_seq, max_decoder_seq_length, num_decoder_tokens)\n",
    "\n",
    "decoder_target_seq = numpy.zeros(decoder_input_seq.shape)\n",
    "decoder_target_seq[:, 0:-1] = decoder_input_seq[:, 1:]\n",
    "decoder_target_data = onehot_encode(decoder_target_seq, \n",
    "                                    max_decoder_seq_length, \n",
    "                                    num_decoder_tokens)\n",
    "\n",
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the networks (for training)\n",
    "\n",
    "- Build encoder, decoder, and connect the two modules to get \"model\". \n",
    "\n",
    "- Fit the model on the bilingual data to train the parameters in the encoder and decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Encoder network\n",
    "\n",
    "- Input:  one-hot encode of the input language\n",
    "\n",
    "- Return: \n",
    "\n",
    "    -- output (all the hidden states   $h_1, \\cdots , h_t$) are always discarded\n",
    "    \n",
    "    -- the final hidden state  $h_t$\n",
    "    \n",
    "    -- the final conveyor belt $c_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Bidirectional, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "latent_dim = 128*3 #was 256\n",
    "\n",
    "# inputs of the encoder network\n",
    "\n",
    "encoder_inputs = Input(shape=(None,num_encoder_tokens), name='encoder_inputs')\n",
    "#if I need to go back to a single layer, return state NOT sequences\n",
    "\n",
    "encoder_bilstm1 = Bidirectional(LSTM(latent_dim, return_sequences=True, \n",
    "                                     dropout=0.25, name='encoder_bilstm1'))(encoder_inputs)\n",
    "\n",
    "_, forward_h, forward_c, backward_h, backward_c  = Bidirectional(LSTM(latent_dim, return_state=True, dropout=0.25,\n",
    "                                                                      name='encoder_bilstm2'))(encoder_bilstm1)\n",
    "state_Eh = Concatenate()([forward_h, backward_h])\n",
    "state_Ec = Concatenate()([forward_c, backward_c])\n",
    "\n",
    "#encoder_states = [state_Eh, state_Ec] # encoder_output discarded\n",
    "\n",
    "# build the encoder network model\n",
    "encoder_model = Model(inputs=encoder_inputs, \n",
    "                      outputs=[state_Eh, state_Ec],\n",
    "                      name='encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After struggling with adding a 2nd layer to the decoder, I found this link and was able to better follow how the model is constructed\n",
    "https://github.com/google/seq2seq/issues/320"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a summary and save the encoder network structure to \"./encoder.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     (None, None, 28)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 768)    1268736     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 768), (None, 3542016     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 768)          0           bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 768)          0           bidirectional_2[0][2]            \n",
      "                                                                 bidirectional_2[0][4]            \n",
      "==================================================================================================\n",
      "Total params: 4,810,752\n",
      "Trainable params: 4,810,752\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "SVG(model_to_dot(encoder_model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(\n",
    "    model=encoder_model, show_shapes=False,\n",
    "    to_file='encoder.pdf'\n",
    ")\n",
    "\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Decoder network\n",
    "\n",
    "- Inputs:  \n",
    "\n",
    "    -- one-hot encode of the target language\n",
    "    \n",
    "    -- The initial hidden state $h_t$ \n",
    "    \n",
    "    -- The initial conveyor belt $c_t$ \n",
    "\n",
    "- Return: \n",
    "\n",
    "    -- output (all the hidden states) $h_1, \\cdots , h_t$\n",
    "\n",
    "    -- the final hidden state  $h_t$ (discarded in the training and used in the prediction)\n",
    "    \n",
    "    -- the final conveyor belt $c_t$ (discarded in the training and used in the prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# inputs of the decoder network\n",
    "decoder_input_h = Input(shape=(latent_dim*2,), name='decoder_input_h')#we ad *2 because we made the encoder bidirectional\n",
    "decoder_input_c = Input(shape=(latent_dim*2,), name='decoder_input_c')\n",
    "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "encoder_state = [decoder_input_h,decoder_input_c]\n",
    "\n",
    "# set the LSTM layer\n",
    "decoder_lstm1_layer = LSTM(latent_dim*2, return_sequences=True, \n",
    "                                    return_state=True, dropout=0.25, name='decoder_lstm1')\n",
    "decoder_lstm1_layer_output, state_hd1,state_cd1= decoder_lstm1_layer(decoder_input_x, initial_state=encoder_state)\n",
    "\n",
    "\n",
    "#decoder_lstm2_layer = LSTM(latent_dim*2,return_sequences=True,  \n",
    "#                                    return_state=True, dropout=0.25, name='decoder_lstm2')\n",
    "#decoder_lstm2_layer_output, state_hd2,state_cd2 = decoder_lstm2_layer(decoder_lstm1_layer_output)\n",
    "                                                #May need to set initial state \n",
    "\n",
    "#Skip_A_Few = Concatenate()([decoder_lstm2_layer_output, decoder_input_x])\n",
    "\n",
    "#Fully_Connected1 = Dense(512, activation='relu', name='Fully_Connected1')\n",
    "#Fully_Connected_Out1 = Fully_Connected1(decoder_lstm2_layer_output) \n",
    "\n",
    "#Fully_Connected2 = Dense(512, activation='relu', name='Fully_Connected2')\n",
    "#Fully_Connected_Out2 = Fully_Connected2(Fully_Connected_Out1) \n",
    "\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_lstm1_layer_output)\n",
    "\n",
    "# build the decoder network model\n",
    "decoder_model = Model(inputs=[decoder_input_x, decoder_input_h, decoder_input_c],\n",
    "                      outputs=[decoder_outputs, state_hd1, state_cd1],\n",
    "                      #outputs=[decoder_outputs],\n",
    "                      name='decoder_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a summary and save the encoder network structure to \"./decoder.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input_x (InputLayer)    (None, None, 30)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_h (InputLayer)    (None, 768)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_c (InputLayer)    (None, 768)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm1 (LSTM)            [(None, None, 768),  2454528     decoder_input_x[0][0]            \n",
      "                                                                 decoder_input_h[0][0]            \n",
      "                                                                 decoder_input_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 30)     23070       decoder_lstm1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,477,598\n",
      "Trainable params: 2,477,598\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "SVG(model_to_dot(decoder_model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(\n",
    "    model=decoder_model, show_shapes=False,\n",
    "    to_file='decoder.pdf'\n",
    ")\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Connect the encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layers\n",
    "encoder_input_x = Input(shape=(None, num_encoder_tokens), name='encoder_input_x')\n",
    "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "# connect encoder to decoder\n",
    "encoder_final_states_h,encoder_final_states_c  = encoder_model([encoder_input_x])\n",
    "decoder_pred,_,_ = decoder_model([decoder_input_x,encoder_final_states_h,encoder_final_states_c])\n",
    "\n",
    "\n",
    "model = Model(inputs=[encoder_input_x, decoder_input_x], \n",
    "              outputs=decoder_pred, \n",
    "              name='model_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_training\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_x (InputLayer)    (None, None, 28)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_x (InputLayer)    (None, None, 30)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 768), (None, 4810752     encoder_input_x[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_model (Model)           [(None, None, 30), ( 2477598     decoder_input_x[0][0]            \n",
      "                                                                 encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "==================================================================================================\n",
      "Total params: 7,288,350\n",
      "Trainable params: 7,288,350\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(\n",
    "    model=model, show_shapes\n",
    "    =False,\n",
    "    to_file='model_training.pdf'\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Fit the model on the bilingual dataset\n",
    "\n",
    "- encoder_input_data: one-hot encode of the input language\n",
    "\n",
    "- decoder_input_data: one-hot encode of the input language\n",
    "\n",
    "- decoder_target_data: labels (left shift of decoder_input_data)\n",
    "\n",
    "- tune the hyper-parameters\n",
    "\n",
    "- stop when the validation loss stop decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of encoder_input_data(30000, 29, 28)\n",
      "shape of decoder_input_data(30000, 58, 30)\n",
      "shape of decoder_target_data(30000, 58, 30)\n"
     ]
    }
   ],
   "source": [
    "print('shape of encoder_input_data' + str(encoder_input_data.shape))\n",
    "print('shape of decoder_input_data' + str(decoder_input_data.shape))\n",
    "print('shape of decoder_target_data' + str(decoder_target_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "temperature = 0.5\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = numpy.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # this line of code is greedy selection\n",
    "        # try to use multinomial sampling instead (with temperature)\n",
    "        output_tokens = output_tokens ** (1 / temperature)        \n",
    "        output_tokens = output_tokens / numpy.sum(output_tokens)\n",
    "     \n",
    "        sampled_token_index = numpy.argmax(output_tokens[0, -1, :])\n",
    "        if(sampled_token_index == 0):      \n",
    "            sampled_token_index=target_token_index['\\n']#replacing 0 with end of string\n",
    "            print(\"Encountered Zero sampled_token_index\")\n",
    "\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "\n",
    "        target_seq = numpy.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testThething(input_sentence):\n",
    "    input_sequence = [input_token_index[n] for n in list(input_sentence.lower())]\n",
    "    while len(input_sequence)<max_encoder_seq_length:\n",
    "        input_sequence.append(0)\n",
    "        \n",
    "    input_x = onehot_encode(numpy.array(input_sequence), max_encoder_seq_length, num_encoder_tokens)\n",
    "    return decode_sequence([[input_x[:,0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 182s 8ms/step - loss: 1.0535 - val_loss: 0.7542\n",
      "Epoch  =  1\n",
      "dat je het geen\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.7582 - val_loss: 0.6326\n",
      "Epoch  =  2\n",
      "deek je het niet\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.6711 - val_loss: 0.5621\n",
      "Epoch  =  3\n",
      "deek je het\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 178s 7ms/step - loss: 0.6130 - val_loss: 0.5124\n",
      "Epoch  =  4\n",
      "dank u tom\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.5658 - val_loss: 0.4766\n",
      "Epoch  =  5\n",
      "bedankt\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 178s 7ms/step - loss: 0.5272 - val_loss: 0.4459\n",
      "Epoch  =  6\n",
      "dank u\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.4961 - val_loss: 0.4222\n",
      "Epoch  =  7\n",
      "bedankt\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.4678 - val_loss: 0.3999\n",
      "Epoch  =  8\n",
      "dank u\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.4453 - val_loss: 0.3886\n",
      "Epoch  =  9\n",
      "dank u\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.4211 - val_loss: 0.3740\n",
      "Epoch  =  10\n",
      "dank u\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.4014 - val_loss: 0.3649\n",
      "Epoch  =  11\n",
      "dank u\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 180s 7ms/step - loss: 0.3837 - val_loss: 0.3541\n",
      "Epoch  =  12\n",
      "dank u\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.3673 - val_loss: 0.3465\n",
      "Epoch  =  13\n",
      "bedankt\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.3516 - val_loss: 0.3428\n",
      "Epoch  =  14\n",
      "bedankt\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.3374 - val_loss: 0.3371\n",
      "Epoch  =  15\n",
      "dank u\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.3234 - val_loss: 0.3337\n",
      "Epoch  =  16\n",
      "bedankt\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.3094 - val_loss: 0.3298\n",
      "Epoch  =  17\n",
      "dank u\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.2989 - val_loss: 0.3289\n",
      "Epoch  =  18\n",
      "dank u\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.2878 - val_loss: 0.3260\n",
      "Epoch  =  19\n",
      "bedankt\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 180s 7ms/step - loss: 0.2778 - val_loss: 0.3265\n",
      "Epoch  =  20\n",
      "dank u\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.2670 - val_loss: 0.3247\n",
      "Epoch  =  21\n",
      "bedankt\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.2577 - val_loss: 0.3268\n",
      "Epoch  =  22\n",
      "bedankt\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.2494 - val_loss: 0.3238\n",
      "Epoch  =  23\n",
      "bedankt\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.2413 - val_loss: 0.3246\n",
      "Epoch  =  24\n",
      "bedankt\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.2320 - val_loss: 0.3231\n",
      "Epoch  =  25\n",
      "bedankt\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.2250 - val_loss: 0.3284\n",
      "Epoch  =  26\n",
      "bedankt\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.2179 - val_loss: 0.3289\n",
      "Epoch  =  27\n",
      "bedankt\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 179s 7ms/step - loss: 0.2105 - val_loss: 0.3316\n",
      "Epoch  =  28\n",
      "dank u\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 183s 8ms/step - loss: 0.2044 - val_loss: 0.3297\n",
      "Epoch  =  29\n",
      "dank u\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "24000/24000 [==============================] - 181s 8ms/step - loss: 0.1989 - val_loss: 0.3337\n",
      "Epoch  =  30\n",
      "bedankt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "model.compile(optimizer=optimizers.rmsprop(learning_rate =0.0005 ), loss='categorical_crossentropy')\n",
    "EPOCHS = 30\n",
    "#model.fit([encoder_input_data, decoder_input_data],  # training data\n",
    "#          decoder_target_data,                       # labels (left shift of the target sequences)\n",
    "#          batch_size=64, epochs=20, validation_split=0.2)\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    model.fit([encoder_input_data, decoder_input_data],  # training data\n",
    "          decoder_target_data,                       # labels (left shift of the target sequences)\n",
    "          batch_size=32, validation_split=0.2)\n",
    "\n",
    "    print(\"Epoch  = \",i+1)\n",
    "    print(testThething('Thank you'))\n",
    "    \n",
    "\n",
    "model.save('seq2seq_2b.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make predictions\n",
    "\n",
    "\n",
    "### 4.1. Translate English to Dutch\n",
    "\n",
    "1. Encoder read a sentence (source language) and output its final states, $h_t$ and $c_t$.\n",
    "2. Take the [star] sign \"\\t\" and the final state $h_t$ and $c_t$ as input and run the decoder.\n",
    "3. Get the new states and predicted probability distribution.\n",
    "4. sample a char from the predicted probability distribution\n",
    "5. take the sampled char and the new states as input and repeat the process (stop if reach the [stop] sign \"\\n\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100\n",
      "English:        they want to talk\n",
      "Dutch (true):  ze willen praten\n",
      "Dutch (pred):  ze willen praten\n",
      "2101\n",
      "English:        frogs eat flies\n",
      "Dutch (true):  kikkers eten vliegen\n",
      "Dutch (pred):  kikkers eten van pizza\n",
      "2102\n",
      "English:        i need a tissue\n",
      "Dutch (true):  ik heb een zakdoek nodig\n",
      "Dutch (pred):  ik heb een taken nodig\n",
      "2103\n",
      "English:        shouldnt we help tom\n",
      "Dutch (true):  moeten we tom niet helpen\n",
      "Dutch (pred):  moeten we tom niet helpen\n",
      "2104\n",
      "English:        tom wont succeed\n",
      "Dutch (true):  tom zal geen succes hebben\n",
      "Dutch (pred):  tom zal niet succeren\n",
      "2105\n",
      "English:        tom respects your opinion\n",
      "Dutch (true):  tom respecteert jouw mening\n",
      "Dutch (pred):  tom respecteert jouw maniaan\n",
      "2106\n",
      "English:        you owe me a kiss\n",
      "Dutch (true):  jullie zijn mij een kus verschuldigd\n",
      "Dutch (pred):  je bent me een kus verschuldigd\n",
      "2107\n",
      "English:        i cant explain it to you now\n",
      "Dutch (true):  ik kan het je nu niet uitleggen\n",
      "Dutch (pred):  ik kan dat niet u helpen of wel\n",
      "2108\n",
      "English:        tom has dark skin\n",
      "Dutch (true):  tom heeft een donkere huid\n",
      "Dutch (pred):  tom heeft ernie ook en\n",
      "2109\n",
      "English:        tom tries\n",
      "Dutch (true):  tom probeert\n",
      "Dutch (pred):  tom probeert\n",
      "2110\n",
      "English:        i live on a small island\n",
      "Dutch (true):  ik woon op een klein eiland\n",
      "Dutch (pred):  ik woon nog een ijsje\n",
      "2111\n",
      "English:        thats too bad\n",
      "Dutch (true):  jammer\n",
      "Dutch (pred):  dat is te gaat\n",
      "2112\n",
      "English:        this pizza is really good\n",
      "Dutch (true):  deze pizza is erg goed\n",
      "Dutch (pred):  deze pizza is erg goed\n",
      "2113\n",
      "English:        tom cried all night\n",
      "Dutch (true):  tom huilde de hele nacht\n",
      "Dutch (pred):  tom huilde de hele nacht\n",
      "2114\n",
      "English:        tom said i could stay\n",
      "Dutch (true):  tom zei dat ik kon blijven\n",
      "Dutch (pred):  tom zei dat ik kon blijven\n",
      "2115\n",
      "English:        just do it\n",
      "Dutch (true):  doe het gewoon\n",
      "Dutch (pred):  doe het gewoon\n",
      "2116\n",
      "English:        this restaurant never closes\n",
      "Dutch (true):  dit restaurant is nooit gesloten\n",
      "Dutch (pred):  dit restaurant is nooit gesloten\n",
      "2117\n",
      "English:        how long was tom at the park\n",
      "Dutch (true):  hoe lang was tom in het park\n",
      "Dutch (pred):  hoe lang was tom in het park\n",
      "2118\n",
      "English:        who helps her\n",
      "Dutch (true):  wie helpt haar\n",
      "Dutch (pred):  wie helpt haar\n",
      "2119\n",
      "English:        tom is your brother\n",
      "Dutch (true):  tom is jouw broer\n",
      "Dutch (pred):  tom is je broer\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(2100, 2120):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    \n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]    \n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(seq_index)\n",
    "    print('English:       ', input_texts[seq_index])\n",
    "    print('Dutch (true): ', target_texts[seq_index][1:-1])\n",
    "    print('Dutch (pred): ', decoded_sentence[0:-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Translate an English sentence to the target language\n",
    "\n",
    "1. Tokenization\n",
    "2. One-hot encode\n",
    "3. Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source sentence is: I love you\n",
      "translated sentence is: ik hou van je\n"
     ]
    }
   ],
   "source": [
    "input_sentence = 'I love you'\n",
    "\n",
    "translated_sentence = testThething(input_sentence)\n",
    "\n",
    "print('source sentence is: ' + input_sentence)\n",
    "print('translated sentence is: ' + translated_sentence[0:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the translation using BLEU score\n",
    "\n",
    "Reference: \n",
    "- https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
    "- https://en.wikipedia.org/wiki/BLEU\n",
    "\n",
    "\n",
    "**Hint:** \n",
    "\n",
    "- Randomly partition the dataset to training, validation, and test. \n",
    "\n",
    "- Evaluate the BLEU score using the test set. Report the average.\n",
    "\n",
    "- A reasonable BLEU score should be 0.1 ~ 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared:: tom loopt rond ::to:: tom wordt aan het lieften\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: hoe laat is het nu ::to:: hoe laat is het nu\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: ik haat mijn zus ::to:: ik haat mijn suisen\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: geef me een sinaasappel ::to:: geef me een fans\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: van wie heb je dit gekregen ::to:: van wie heb je dit gebroken\n",
      " ::BLEU Score = 0.759836\n",
      "Compared:: je rijdt te snel ::to:: je dertreken te schrijven\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik ben wie ik ben ::to:: ik ben in ik ook\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik denk dat tom een student is ::to:: ik denk dat tom een stima is\n",
      " ::BLEU Score = 0.643459\n",
      "Compared:: tom is een vriendelijk persoon ::to:: tom is een vriendelijk persoon\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: ze wonen aan de overkant van de rivier ::to:: zij wonen dicht bij de rivier\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: waarom is de hemel blauw ::to:: waarom is de bus bestugeng\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: doe uw schoenen uit ::to:: doe je sokken aan\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: waar is het boek ::to:: waar is de boek\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: vandaag past niet voor mij ::to:: vandaag is het niet moet moe\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: telefoneer mij deze avond ::to:: bel me vanavond\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: wat is jouw lievelingsauto ::to:: wat is je lievelingsangel\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: daarom zijn wij hier ::to:: daarom wijn we hier\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: vind je dit een mooie kleur ::to:: vind je deze kleur leuk\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: wij eten vis rauw ::to:: we hebben elkaar veil genien\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: hij is in het examen gezakt ::to:: hij verfde de muid\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: misschien zou jij moeten rijden ::to:: misschien ben je altijd verenden\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik help u ::to:: ik zal u helpen\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom is geen vegetarier ::to:: tom is geen vegetarier\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: ik wil helemaal niemand ::to:: ik wil helemaal niemand\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: tom is sexy ::to:: tom is thee aan het roken\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: het is donker in deze kamer ::to:: het is van ie de kamer\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom ademde uit ::to:: tom beedde\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom meende wat hij zei ::to:: tom wiet wat hij zei\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik wil nog eens proberen ::to:: ik wil een tanderen gaan\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik groeide op in de bergen ::to:: ik ben opgegroeid in de zookte\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: waar heb je gewoond ::to:: waar woonde je\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: waarom werd tom zo boos ::to:: waarom wordt tom zo boos\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik ben hier aan het eten ::to:: ik eet hier\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom is in in boston gestorven ::to:: tom is gestorven niet in boston\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik moet een brief schrijven ::to:: ik moet een brief schrijven\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: hij weigerde commentaar te geven ::to:: hij begonierte tom in australie\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: over uur komen we opnieuw samen ::to:: over drie uur ons een eer geweert\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom is niet in orde ::to:: tom is nogal\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: het is mogelijk dat tom liegt ::to:: het is neeflijk te zoon tom achter\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik woon in de stad ::to:: ik woon in de stad\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: zie je de beer ::to:: ziet u de beer\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik ben allergisch voor wortels ::to:: ik ben allergisch voor mindas\n",
      " ::BLEU Score = 0.668740\n",
      "Compared:: praat je over ons ::to:: spreek je over\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik zou je niet de schuld geven ::to:: ik zou je niet verleten\n",
      " ::BLEU Score = 0.448270\n",
      "Compared:: ik voel me net een klein kind ::to:: ik voel me veel een beetje kinkeren\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik hou van italiaans eten ::to:: ik hou van italiaans eten\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: goed weekeinde ::to:: prettig weekend\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: je bent beter geworden ::to:: je hebt bestere  eraakt\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: is dit alles wat u heeft meneer ::to:: is dit jullie oud wes\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ze lijkt gelukkig ::to:: ze ziet er gelukkig uit\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ze is net vertrokken ::to:: ze is net weggegaan\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: je houdt niet van muziek ::to:: je houdt niet van muziek\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: is alles in orde hier ::to:: is alles daar\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom heeft hooikoorts ::to:: tom heeft vroegen hoefde\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: wil je het zien ::to:: wil je het zien\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: je bent humeurig ::to:: je bent meer\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ze zijn heel groot ::to:: ze zijn erg bedig\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik heb spijt om wat ik gedaan heb ::to:: sorry dat ik ze lant was ik doen\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: wil je meer ijs ::to:: wilt u meer ijs\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: de klok sloeg tien ::to:: de klok stopt er steekt\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: is dat jullie broer ::to:: is dat jouw broer\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: thomas kookt een ei ::to:: tom is een haal aan het lezen\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: bent u goed in skien ::to:: zijn jullie goed in skien\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: vier keer vijf is twintig ::to:: uw vriend is notimde is ijs\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ze hebben niets gemeen ::to:: ze hebben niets veer temank\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: hij was zeer lief voor hen ::to:: hij was erg doe vanden\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: kun je cursief schrijven ::to:: kunn u richtscorijnen\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: doe het nog een keer ::to:: doe het nog eens\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: titanic is mijn favoriete film ::to:: dit lant is mijn lievelingsspel\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: cacao kan heel bitter zijn ::to:: sonien kan erg goed veienen\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: dat ga ik kopen ::to:: ik zal die twee eren\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ge zoudt beter slapen ::to:: je moet moeten gaan\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: de vrachtwagen botste tegen een auto ::to:: de vrouw heeft een kuto gebal\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: het spijt me werkelijk ::to:: het spijt me darkelijk\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: het kan me allemaal niet meer schelen ::to:: het maakt me allemaal niet meer uit\n",
      " ::BLEU Score = 0.434721\n",
      "Compared:: rookt jullie vader ::to:: rookt jouw vader\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik zou nu graag alleen zijn ::to:: ik zou graag naar bed ging waar\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik eet niet zo veel vlees ::to:: ik eet geen valleden\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: suiker lost op in water ::to:: somst stond is water\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: kijk recht vooruit ::to:: kijk naar de hond\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom is een slager ::to:: tom is een stief\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik heb al een vriendin ::to:: ik heb een vroendinder\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: vertrouwt u haar ::to:: heeft u hier bij\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: het is een geschenk voor u ::to:: deze hoffi is van jou\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: toms auto vloog in brand ::to:: toms hund is voor aan het leeften\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom begon te snurken ::to:: tom begon te hoelen\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: hoe laat gaat hij dicht ::to:: het hooft hie heet is af\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: mijn verzoek werd geweigerd ::to:: mijn ouders was ondergekend\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: die jongen is erg slim ::to:: die jongen is erg snel\n",
      " ::BLEU Score = 0.668740\n",
      "Compared:: hebben jullie gedoucht ::to:: heb je gedronken\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: zorg voor tom ::to:: kijk naar tom\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: het lukte hem te ontsnappen ::to:: hij kwnm te ontsnappen\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik kocht een mooi horloge voor mezelf ::to:: ik heb de eel ficht gekocht\n",
      " ::BLEU Score = 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared:: ik geloof stellig daarin ::to:: ik heb dat gelekend dat gelogen\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik wil iets zoets ::to:: ik wil iets te enee\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: waar is er tandpasta ::to:: waar kan ik niets voorstellen\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik vertrouw niemand hier ::to:: ik vertrouw hier niemand\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: begrijp je wat ik wil zeggen ::to:: vergeten jullie dat ik wie\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: wat is uw bloedgroep ::to:: wat is jullie bliddoom\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ik denk dat tom zal winnen ::to:: ik denk dat tom niet gaan weggen\n",
      " ::BLEU Score = 0.411134\n",
      "The Avaerage BLEU Score for the test set is: 0.130349\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "\n",
    "# Test sentences\n",
    "\n",
    "#print(\"Printing The first 10 Test Samples:\\n\")\n",
    "#for i in range(10):\n",
    "    #print('[' + Test_pairs[i, 0] + '] => [' + Test_pairs[i, 1] + ']')\n",
    "\n",
    "MyBleuScore = 0.0\n",
    "\n",
    "for i in range(TestSize):\n",
    "    weights=(0.25, 0.25, 0.25, 0.25)\n",
    "    reference = [Test_pairs[i, 1].split(' ')]\n",
    "    \n",
    "    #We do the translation here\n",
    "    translated_sentence = testThething(Test_pairs[i, 0])            \n",
    "    candidate = translated_sentence[0:-1].split(' ')#so we can drop the \\n\n",
    "    \n",
    "    #Borrowed section on dealing with short grams from https://github.com/nltk/nltk/issues/1554\n",
    "    if len(candidate)<4:\n",
    "        weights = ( 1 / (len(candidate)) ,) * (len(candidate))\n",
    "        LastBleuScore = sentence_bleu(reference, candidate,weights)\n",
    "    else:\n",
    "        LastBleuScore = sentence_bleu(reference, candidate)\n",
    "    \n",
    "    print(\"Compared::\",Test_pairs[i, 1], \"::to::\", translated_sentence, \"::BLEU Score = %f\" %LastBleuScore)\n",
    "    MyBleuScore += LastBleuScore\n",
    "\n",
    "MyBleuScore = MyBleuScore/TestSize\n",
    "\n",
    "print(\"The Avaerage BLEU Score for the test set is: %f\" %MyBleuScore )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
