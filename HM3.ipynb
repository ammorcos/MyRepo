{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 3: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Amir Morcos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    \n",
    "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo.\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2019F/blob/master/homework/HM3/HM3.html\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    RetArray = numpy.zeros((len(y),num_class))\n",
    "    for i in y:\n",
    "         RetArray[i,y[i]] = 1 #there should be a better way to do this though list comprehension, I just cant think of it \n",
    "    \n",
    "    return RetArray\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]/255.0 #Added this to make it between zero and 1\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]/255.0\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,343,146\n",
      "Trainable params: 1,342,698\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((3, 3)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-5 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              #optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              #optimizer=optimizers.adam(),\n",
    "              optimizer=optimizers.SGD(learning_rate=learning_rate, momentum=0.1),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "40000/40000 [==============================] - 13s 332us/step - loss: 6.6524e-04 - acc: 0.0010 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 2/25\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 6.9673e-04 - acc: 0.0036 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 3/25\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 8.1120e-04 - acc: 0.0133 - val_loss: 0.0000e+00 - val_acc: 0.0011\n",
      "Epoch 4/25\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 7.7052e-04 - acc: 0.0288 - val_loss: 0.0000e+00 - val_acc: 0.0165\n",
      "Epoch 5/25\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 6.2237e-04 - acc: 0.0501 - val_loss: 0.0000e+00 - val_acc: 0.0623\n",
      "Epoch 6/25\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 7.2393e-04 - acc: 0.0671 - val_loss: 0.0000e+00 - val_acc: 0.1203\n",
      "Epoch 7/25\n",
      "40000/40000 [==============================] - 10s 254us/step - loss: 7.1340e-04 - acc: 0.0809 - val_loss: 0.0000e+00 - val_acc: 0.1547\n",
      "Epoch 8/25\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 7.4997e-04 - acc: 0.0861 - val_loss: 0.0000e+00 - val_acc: 0.1307\n",
      "Epoch 9/25\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 8.4176e-04 - acc: 0.0873 - val_loss: 0.0000e+00 - val_acc: 0.0846\n",
      "Epoch 10/25\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 0.0010 - acc: 0.0893 - val_loss: 0.0000e+00 - val_acc: 0.0493\n",
      "Epoch 11/25\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 9.1130e-04 - acc: 0.0912 - val_loss: 0.0000e+00 - val_acc: 0.0275\n",
      "Epoch 12/25\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 0.0013 - acc: 0.0953 - val_loss: 0.0000e+00 - val_acc: 0.0116\n",
      "Epoch 13/25\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 0.0011 - acc: 0.0965 - val_loss: 0.0000e+00 - val_acc: 9.0000e-04\n",
      "Epoch 14/25\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 0.0016 - acc: 0.0980 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 15/25\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 0.0042 - acc: 0.0988 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 16/25\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: nan - acc: 0.3104 - val_loss: nan - val_acc: 1.0000\n",
      "Epoch 17/25\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: nan - acc: 0.9998 - val_loss: nan - val_acc: 1.0000\n",
      "Epoch 18/25\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: nan - acc: 0.9998 - val_loss: nan - val_acc: 1.0000\n",
      "Epoch 19/25\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: nan - acc: 0.9998 - val_loss: nan - val_acc: 1.0000\n",
      "Epoch 20/25\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: nan - acc: 0.9998 - val_loss: nan - val_acc: 1.0000\n",
      "Epoch 21/25\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: nan - acc: 0.9998 - val_loss: nan - val_acc: 1.0000\n",
      "Epoch 22/25\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: nan - acc: 0.9998 - val_loss: nan - val_acc: 1.0000\n",
      "Epoch 23/25\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: nan - acc: 0.9998 - val_loss: nan - val_acc: 1.0000\n",
      "Epoch 24/25\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: nan - acc: 0.9998 - val_loss: nan - val_acc: 1.0000\n",
      "Epoch 25/25\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: nan - acc: 0.9998 - val_loss: nan - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_tr, y_tr, batch_size=64, epochs=25, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3hU9bX/8fdKQCHcRMB6SiShVk+VSCBErIqi1eKlLdZbkQefKnrkp/VCay+HFo96PKUXq9Va/bXiqa1HUim9aMEiVv15qdVWAhotcCyUWyMIERNuQSCwfn/syTiEmWRmMjuTmfm8nmeemb1n75m1M7DXfL/f+a5t7o6IiAhAUbYDEBGR7kNJQUREopQUREQkSklBRESilBRERCSqR7YDSNXgwYO9vLw822GIiOSUJUuWvOfuQzraLueSQnl5ObW1tdkOQ0Qkp5jZumS2U/eRiIhEKSmIiEiUkoKIiETl3JhCPHv37qW+vp4PPvgg26FIO3r16kVpaSk9e/bMdigikkBeJIX6+nr69etHeXk5ZpbtcCQOd2fLli3U19czfPjwbIcjIgmE1n1kZg+b2WYz+1uC583M7jOzVWb2pplVpfteH3zwAYMGDVJC6MbMjEGDBqk1183V1EB5ORQVBfc1Nd1jH8WV+j5pc/dQbsDpQBXwtwTPnw88BRjwSeCvybzumDFjvK3ly5cftE66J31W3decOe4lJe7w4a2kJFifzX0UV+r7xAPUehLnWPMQS2ebWTnwpLtXxHnuQeAFd38ssvw2cIa7b2zvNaurq73tPIUVK1Zw3HHHZSpsCZE+qy62Zw/86EewfXuHm5bfdzPrth520PqyAU2svemHWdtHcSXYpwzWro27S1xmtsTdqzvcMJnMke4NKCdxS+FJYFzM8nNAdYJtpwG1QO2wYcMOyoDZ/vY5fvx4X7Ro0QHr7rnnHr/uuuva3a9Pnz7u7v7OO+/4xRdfnPC1Fy9e3O7r3HPPPb5z587o8nnnneeNjY3JhN7lsv1ZFZwXX/zw66VZuzdj3wHfRqO7sS+r+yiuBPtYav8USLKlkM2fpMYbAIjbbHH32e5e7e7VQ4Z0OEu7y02ePJm5c+cesG7u3LlMnjw5qf0/+tGP8pvf/Cbt97/33ntpbm6OLi9cuJDDDjv4m4UUoPffD+5ffx3272/3Nqws/ulgWFlRVvdRXAn2GRZ3dadlMynUA0fFLJcCG7IUS6dccsklPPnkk+zevRuAtWvXsmHDBsaNG8eOHTs466yzqKqq4oQTTuD3v//9QfuvXbuWioqgh23Xrl1cdtlljBw5kkmTJrFr167odtdddx3V1dWMGDGC2267DYD77ruPDRs2cOaZZ3LmmWcCQSmQ9957D4Af/vCHVFRUUFFRwb333ht9v+OOO45rrrmGESNGMGHChAPep9WCBQs46aSTGD16NGeffTabNm0CYMeOHUydOpUTTjiBkSNH8tvf/haARYsWUVVVRWVlJWeddVZG/rbSSY2NwX0SXxJmzYKSkgPXlZQE67O5j+JKfZ9OSaY5ke6N9ruPPsOBA82vJfOaHQ40T5/uPn58Zm/Tp3fYNDv//PP9iSeecHf37373u/61r33N3d337t3rW7dudXf3hoYGP/roo33//v3u/mH30Zo1a3zEiBHu7n733Xf71KlT3d29rq7Oi4uLo91HW7ZscXf3lpYWHz9+vNfV1bm7e1lZmTc0NERjaV2ura31iooK37Fjh2/fvt2PP/54X7p0qa9Zs8aLi4v99ddfd3f3Sy+91B999NGDjun999+PxvrQQw/5zTff7O7u3/jGN3x6zN/k/fff982bN3tpaamvXr36gFjbUvdRF/vhD4O+hiS7E+fMcS8rC7omysqSG8zsin0UV+r7tEWS3UehzVMws8eAM4DBZlYP3Ab0jCSinwILCX6BtApoBqaGFUtXaO1CuuCCC5g7dy4PP/wwECTdb33rW7z00ksUFRXxzjvvsGnTJo488si4r/PSSy9x0003ATBy5EhGjhwZfW7evHnMnj2blpYWNm7cyPLlyw94vq2XX36ZCy+8kD59+gBw0UUX8ac//YmJEycyfPhwRo0aBcCYMWNYG2fEqr6+nkmTJrFx40b27NkTnV/w7LPPHtBdNnDgQBYsWMDpp58e3ebwww9P9k8nYWpqAjPo3z+pzadMCW6p6Ip9FFfq+6QrtKTg7u12qEcy1/UZf+NIF0lX+/znP8/NN9/M0qVL2bVrF1VVwbSLmpoaGhoaWLJkCT179qS8vLzD3+rHm2+xZs0a7rrrLhYvXszAgQO58sorO3yd4E8c36GHHhp9XFxcHLf76MYbb+Tmm29m4sSJvPDCC9x+++3R120bY7x10g00NsKAAcEP3EWSoH8pGdK3b1/OOOMMrrrqqgMGmLdu3coRRxxBz549ef7551m3rv3qtaeffjo1kZkpf/vb33jzzTcB2LZtG3369GHAgAFs2rSJp556KrpPv3792B7nJ4enn346TzzxBM3NzezcuZPHH3+c0047Lelj2rp1K0OHDgXgkUceia6fMGEC999/f3S5sbGRk08+mRdffJE1a9YA8H7rAKdkV1MTDByY7SgkhygpZNDkyZOpq6vjsssui66bMmUKtbW1VFdXU1NTwyc+8Yl2X+O6665jx44djBw5kjvvvJOxY8cCUFlZyejRoxkxYgRXXXUVp556anSfadOmcd5550UHmltVVVVx5ZVXMnbsWE466ST+7d/+jdGjRyd9PLfffjuXXnopp512GoMHD46uv+WWW2hsbKSiooLKykqef/55hgwZwuzZs7nooouorKxk0qRJSb+PhKixMalBZpFWoU5eC4Mmr+U2fVZd7LTT4JBD4Lnnsh2JZFmyk9fUUhDJZ2opSIqUFETyWVOTkoKkRElBJJ9poFlSpKQgkq/27oWdO9VSkJQoKYjkq6am4F4tBUmBkoJIvkqh7pFIKyWFDNiyZQujRo1i1KhRHHnkkQwdOjS6vGfPnqReY+rUqbz99tvtbvPAAw9EJ7aJdEgtBUlDXlyjOVU1NTBzJqxfH5SfnTWrc3VFBg0axBtvvAEEE7769u3L1772tQO2aS02VZSg3MDPf/7zDt/n+uszXxVE8lhrUlBLQVJQcC2FmhqYNg3WrQsuVbFuXbAcxhfwVatWUVFRwbXXXktVVRUbN25k2rRp0fLXd9xxR3TbcePG8cYbb9DS0sJhhx3GjBkzqKys5OSTT2bz5s1AMJO4tfz1uHHjmDFjBmPHjuVf//VfeeWVVwDYuXMnF198MZWVlUyePJnq6upowop12223ceKJJ0bja53E+Pe//51PfepTVFZWUlVVFS2U953vfIcTTjiByspKZs6cmfk/lmSeuo8kDQWXFGbOhJjr0QDBcljnueXLl3P11Vfz+uuvM3ToUL73ve9RW1tLXV0dzzzzDMuXLz9on61btzJ+/Hjq6uo4+eSToxVX23J3XnvtNX7wgx9EE8yPf/xjjjzySOrq6pgxYwavv/563H2nT5/O4sWLeeutt9i6dSuLFi0CglIdX/nKV6irq+OVV17hiCOOYMGCBTz11FO89tpr1NXV8dWvfjVDfx0JlbqPJA0FlxTWr09tfWcdffTRnHjiidHlxx57jKqqKqqqqlixYkXcpNC7d2/OO+88IHFZawhKYbfd5uWXX47WXqqsrGTEiBFx933uuecYO3YslZWVvPjiiyxbtozGxkbee+89Pve5zwHQq1cvSkpKePbZZ7nqqqvo3bs3oLLYOUMtBUlDwY0pDBsWdBnFWx+G1msZAKxcuZIf/ehHvPbaaxx22GFcfvnlcctfH3LIIdHHxcXFtLS0xH3t1vLXsdskU8uqubmZG264gaVLlzJ06FBuueWWaBzxyl+rLHaOamqCQw+FSDIXSUbBtRS6/NJ2MbZt20a/fv3o378/Gzdu5Omnn874e4wbN4558+YB8NZbb8VtiezatYuioiIGDx7M9u3bo5fTHDhwIIMHD2bBggUAfPDBBzQ3NzNhwgR+9rOfRa+5oLLYOUJ1jyQNBZcUpkyB2bOhrCy4IFVZWbDcFVc1qqqq4vjjj6eiooJrrrnmgPLXmXLjjTfyzjvvMHLkSO6++24qKioYMGDAAdsMGjSIK664goqKCi688EJOOumk6HM1NTXcfffdjBw5knHjxtHQ0MBnP/tZzj33XKqrqxk1ahT33HNPxuOWEKjEhaRBpbPzTEtLCy0tLfTq1YuVK1cyYcIEVq5cSY8e3aOnUJ9VFzrnHNi2DV59NduRSDeQbOns7nGmkIzZsWMHZ511Fi0tLbg7Dz74YLdJCNLFGhth0KBsRyE5RmeLPHPYYYexZMmSbIch3UFTE3z849mOQnJM3owp5Fo3WCHSZ9TFNNAsaciLpNCrVy+2bNmik0435u5s2bKFXr16ZTuUwuCugWZJS150H5WWllJfX09DQ0O2Q5F29OrVi9LS0myHURh27oSWFrUUJGV5kRR69uzJ8OHDsx2GSPehYniSprzoPhKRNlT3SNKkpCCSj1T3SNKkpCCSj9RSkDQpKYjkI7UUJE1KCiL5SC0FSZOSgkg+am0p9O+f3Tgk5ygpiOSjpibo1w9U90pSFGpSMLNzzextM1tlZjPiPD/MzJ43s9fN7E0zOz/MeEQKhmYzS5pCSwpmVgw8AJwHHA9MNrPj22x2CzDP3UcDlwH/N6x4RAqK6h5JmsJsKYwFVrn7anffA8wFLmizjQOtnZ4DgA0hxiNSONRSkDSFmRSGAv+MWa6PrIt1O3C5mdUDC4Eb472QmU0zs1ozq1V9I5EkqKUgaQozKcS70nvbMqaTgV+4eylwPvComR0Uk7vPdvdqd68eMmRICKGK5Bm1FCRNYSaFeuComOVSDu4euhqYB+DurwK9gMEhxiRSGNRSkDSFmRQWA8eY2XAzO4RgIHl+m23WA2cBmNlxBElB/UMindHSAtu3KylIWkJLCu7eAtwAPA2sIPiV0TIzu8PMJkY2+ypwjZnVAY8BV7qulCPSOdu2BffqPpI0hDqzxd0XEgwgx667NebxcuDUMGMQKTiqeySdoBnNIvlGdY+kE5QURPKNWgrSCUoKIvlGLQXpBCUFkXyj6zNLJygpiOQbdR9JJygpiOSbpqagZHafPtmORHKQkoJIvmmdzWzxKs2ItE9JQSTfqO6RdIKSgki+Ud0j6QQlBZF8o5aCdIKSgki+aWpSS0HSpqQgkm/UfSSdoKQgkm/UfSSdoKQgkk927YLdu9VSkLQpKYjkE9U9kk5SUhDJJypxIZ2kpCCST1QMTzpJSUEkn6j7SDpJSUEkn6j7SDpJSUEkn6ilIJ2kpCCST9RSkE5SUhDJJ01NwXUUevbMdiSSo5QURPKJSlxIJykpiOQTFcOTTlJSEMknqnsknaSkIJJP1H0knaSkIJJP1FKQTlJSEMknailIJykpiOSL/fth61a1FKRTlBRE8sX27eCuloJ0SqhJwczONbO3zWyVmc1IsM0XzGy5mS0zs1+GGY9IXtNsZsmAHmG9sJkVAw8AnwbqgcVmNt/dl8dscwzwTeBUd280syPCikck76nukWRAmC2FscAqd1/t7nuAucAFbba5BnjA3RsB3H1ziPGI5De1FCQDOkwKZnaDmaXz1WMo8M+Y5frIuljHAsea2Z/N7C9mdm6CGKaZWa2Z1TY0NKQRikgBUEtBMiCZlsKRBF0/8yJjBJbka8fbztss9wCOAc4AJgP/bWYHfc1x99nuXu3u1UOGDEny7UUKjFoKkgEdJgV3v4XgxP0z4EpgpZl9x8yO7mDXeuComOVSYEOcbX7v7nvdfQ3wduS9RCRVailIBiQ1puDuDrwbubUAA4HfmNmd7ey2GDjGzIab2SHAZcD8Nts8AZwJYGaDCbqTVqd0BCISaGqCoiLo2zfbkUgOS2ZM4SYzWwLcCfwZOMHdrwPGABcn2s/dW4AbgKeBFcA8d19mZneY2cTIZk8DW8xsOfA88HV339KpIxIpVI2NMGBAkBhE0pTMT1IHAxe5+7rYle6+38w+296O7r4QWNhm3a0xjx24OXITkc5Q3SPJgGS+UiwE3m9dMLN+ZnYSgLuvCCswEUmR6h5JBiSTFH4C7IhZ3hlZJyLdiVoKkgHJJAWLdPMAQbcRIc6EFpE0qaUgGZBMUlgdGWzuGblNR78QEul+dClOyYBkksK1wCnAOwTzCk4CpoUZlIikQd1HkgEddgNF6hFd1gWxiEi69uyB5ma1FKTTOkwKZtYLuBoYAfRqXe/uV4UYl4ikQrOZJUOS6T56lKD+0TnAiwTlKraHGZSIpEh1jyRDkkkKH3f3/wB2uvsjwGeAE8INS0RSopaCZEgySWFv5L7JzCqAAUB5aBGJSOrUUpAMSWa+wezI9RRuISho1xf4j1CjEpHUtLYUlBSkk9pNCmZWBGyLXBntJeBjXRKViKRG3UeSIe12H0VmL9/QRbGISLrUfSQZksyYwjNm9jUzO8rMDm+9hR6ZiCSvqQl69QpuIp2QzJhC63yE62PWOepKEuk+VPdIMiSZGc3DuyIQEekElbiQDElmRvMX46139//JfDgikhYVw5MMSab76MSYx72As4ClgJKCSHfR2AhDhmQ7CskDyXQf3Ri7bGYDCEpfiEh30dQExx6b7SgkD6Rzhe9m4JhMByIinaCBZsmQZMYUFhD82giCJHI8MC/MoEQkBe4aaJaMSWZM4a6Yxy3AOnevDykeEUnVjh2wb59aCpIRySSF9cBGd/8AwMx6m1m5u68NNTIRSY5KXEgGJTOm8Gtgf8zyvsg6EekOVAxPMiiZpNDD3fe0LkQeHxJeSCKSEtU9kgxKJik0mNnE1gUzuwB4L7yQRCQl6j6SDEpmTOFaoMbM7o8s1wNxZzmLSBaopSAZlMzktX8AnzSzvoC5u67PLNKdqKUgGdRh95GZfcfMDnP3He6+3cwGmtm3uyI4EUlCa0uhf//sxiF5IZkxhfPcval1IXIVtvPDC0lEUtLUFCSE4uJsRyJ5IJmkUGxmh7YumFlv4NB2theRrqTZzJJBySSFOcBzZna1mV0NPAM8ksyLm9m5Zva2ma0ysxntbHeJmbmZVScXtohEqe6RZFAyA813mtmbwNmAAYuAso72M7Ni4AHg0wS/WFpsZvPdfXmb7foBNwF/TT18EVFLQTIp2Sqp7xLMar6Y4HoKK5LYZyywyt1XRya8zQUuiLPdfwF3Ah8kGYuIxFJLQTIoYVIws2PN7FYzWwHcD/yT4CepZ7r7/Yn2izE0sk+r+si62PcYDRzl7k+290JmNs3Mas2stqGhIYm3FikgailIBrXXUvhfglbB59x9nLv/mKDuUbIszjqPPmlWBNwDfLWjF3L32e5e7e7VQ3R1KZEDqaUgGdReUriYoNvoeTN7yMzOIv6JPpF64KiY5VJgQ8xyP6ACeMHM1gKfBOZrsFkkBS0tQelsJQXJkIRJwd0fd/dJwCeAF4CvAB8xs5+Y2YQkXnsxcIyZDTezQ4DLgPkxr7/V3Qe7e7m7lwN/ASa6e236hyNSYLZuDe7VfSQZ0uFAs7vvdPcad/8swbf9N4CEPy+N2a8FuAF4mmBgep67LzOzO2IL7IlIJ6jukWRYMgXxotz9feDByC2Z7RcCC9usuzXBtmekEouIoLpHknHJ/iRVRLojtRQkw5QURHKZWgqSYUoKIrlMLQXJMCUFkVym6zNLhikpiOSypibo2RNKSrIdieQJJQWRXNY6m9lSmVcqkpiSgkguU90jyTAlBZFcprpHkmFKCiK5TC0FyTAlBZFc1tTUbkuhpgbKy6GoKLivqemyyCRHpVTmQkS6mXa6j2pqYNo0aG4OltetC5YBpkzpovgk56ilIJKr3NvtPpo588OE0Kq5OVgvkoiSgkiu2rUL9uxJ2FJYvz7+bonWi4CSgkju6qDu0bBh8XdLtF4ElBREclcHdY9mzTp4onNJSbBeJBElBZFc1UFLYcoUmD0bysqCCc9lZcGyBpmlPfr1kUiuSqIY3pQpSgKSGrUURHKVymZLCJQURHKVLrAjIVBSEMlVrS2FAQOyG4fkFSUFkVzV1AR9+wbXUxDJECUFkVylCqkSAiUFkVzVQTE8kXQoKYjkKpXNlhAoKYjkKnUfSQiUFERylVoKEgIlBZFcpZaChEBJQSQX7d8P27appSAZp6Qgkou2bg0usqOWgmSYkoJILkqiGJ5IOkJNCmZ2rpm9bWarzGxGnOdvNrPlZvammT1nZmVhxiOSN1T3SEISWlIws2LgAeA84Hhgspkd32az14Fqdx8J/Aa4M6x4RPKKKqRKSMJsKYwFVrn7anffA8wFLojdwN2fd/fWS4v/BSgNMR6R/KGWgoQkzKQwFPhnzHJ9ZF0iVwNPxXvCzKaZWa2Z1TY0NGQwRJEcpZaChCTMpGBx1nncDc0uB6qBH8R73t1nu3u1u1cPGTIkgyGK5Ci1FCQkYV6Osx44Kma5FNjQdiMzOxuYCYx3990hxiOSP5qaoKgoKJ0tkkFhthQWA8eY2XAzOwS4DJgfu4GZjQYeBCa6++YQYxHJL62zmS1eg1wkfaElBXdvAW4AngZWAPPcfZmZ3WFmEyOb/QDoC/zazN4ws/kJXk5EYqnukYQkzO4j3H0hsLDNultjHp8d5vuL5C3VPZKQaEazSC5SS0FCoqQgkovUUpCQKClIfJs2wa9/De+9l+1IJB61FCQkSgpyoG3b4NZb4eij4QtfgI9+FC6+GBYsgL17sx2dtNL1mSUkSgoS2L0bfvSjIBn813/BZz4Df/wj3HgjvPwyTJwIpaXw1a/Cm29mO9rCtns37NqlpCChUFIodPv2waOPwic+AV/+MowaBbW18Ktfwac/DXffDfX1MH8+jBsHP/4xVFZCVRXcd5+6l7JBs5klREoKhcodFi6E0aPhi1+EQYPgmWeC25gxB27bsyd87nPw29/Cxo1BYigqgunTg+6liy4Kkoa6l7qG6h5JiJQUCtFf/gJnnBF0ETU3w9y58NprcHYS00YGDYIbbghaE2+9FSSGV16BCy6AoUPh9tthz56wj6CwqaUgIVJSKCQrVsCFF8LJJ8Pbb8MDDwTrJk0KvvmnqqICfvCDoHvpySfh1FPhP/8zuF+5MvPxS0AtBQmRkkIh2LULrr02OIk/91wwkLxqFXzpS0HXUGf16BG0Oh5/HH73O1i9OuiW+sUvgm4qySxdilNCpKSQ7xobYcIEmD07+CXR6tVwyy3hVde88EKoq4MTT4SpU2Hy5A9PYpIZ6j6SECkp5LN33oHTT4e//jUYN7j3Xhg8OPz3LS2FZ5+F7343GJyurAx+1iqdUlMD5eVQ9KVrKWcNNYsOz3ZIkoeUFPLV//4vnHIKrFsHixYFE9G6UnExzJgBf/5z0EU1fnwwCN3S0rVxpCF68i0K7mtqMrt9uu8xbVrwcTrGOsqZ9qWeSb2XSErcPaduY8aMcenAq6+6H364+0c+4r50abajcd+2zf2KK9zB/ZRT3NesSetl5sxxLytzNwvu58zJ/D5z5riXlAShtt5KShLvl+r26e5TVnbg9q23srL2j0ekFVDrSZxjs36ST/WmpNCBP/zBvXdv96OPdv/HP7rsbZM6+f7yl+79+we3xx5L6YTdXU++6Zys09nHLP4+Zon3EYmlpFCIfv5z9+Ji96oq93ffTftlQv12vWaN+ymn+Bwme0nxB0mfsLvryTedk3U6+6ilIJ2lpFBI9u93/973go/z7LOD7po0dUnXxt69XjagMaV9uuvJt6uSVTqfi0gsJYVCsW+f+/TpwUc5ebL77t2dermu6tpIdZ/uevLtqm6t1v3KytyNfV5WslkJQVKipFAIdu8OEgG4f/nLQYKII5XuoK7q2ki4T9/33DdsiHsMXX7yTaH7LOwB8AMcfrj79densIOIkkL+27Yt6CoC9+9/P+hCiiPVE2NXdW3E3afHbp9jl7v36eN+223u27cftE+Xnny7o/373YuK3G+5JduRSI5RUshnmza5jxkTDCr/4hftbprqSb6rvl0n3GflSvdLLgne+Mgj3R980H3v3o5frFBs3Rr8be66K9uRSI5RUshTc2Yu87Lifwb9ykN2dnjyTac7qFt8u371VfdTTw2CPe449/nzE7aGCsq6dcHf5Gc/y3YkkmOSTQqa0Zwr9u6l5oJfMW1WGev2leIUsa6hhGnT2p8NO2xYausBpkyBtWth//7gfsqUzgSepk9+Ev70p6DAXktLcOW3M88MSnYXMlVIlZApKeSClSvhlFOYOf8kmulzwFPNzTBzZuJdZ82CkpID15WUBOu7PbOgwN6yZXD//bB8eVBob9KkoNprDpTMyDhVSJWQKSl0Z+7w8MNBGep//IP1VhZ3s/XrE7/ElClBgdSysuAcW1YWLGfl23+6evaE668Pyn3PnAl/+ENwQaChQ4P1L70UNGsKgSqkSsiUFLKo3aJojY1BEburr4axY+HNNxk2zOK+TntdQdBNuoMyoX9/+Pa3YfNm+PWvgwqwP/95UGzvqKOCa0y/+mqQTPOVuo8kZEoKWXJA1UsP7qPjAy+8ACNHwhNPwPe/H1w3ubQ0t7uCMqmkBC65JEgMmzfDL38ZdCv95CdBZdjycvj614Pxh3xLEGopSMiUFLJk5sxgPCBWczPM/FIjfOpTwYnvL3+Bb3wjKENNnnQFZVrfvsGFfJ54IkgQjzwSXGHu3nuDRHHMMfCtbwUJYt++bEfbeY2NwYffv3+2I5E8paSQQanUyE80DrB+24Cgy2jpUhgz5qDn86YrKAwDBsAXvxiMOWzaBP/93/Cxj8GddwYJYtAg+Oxn4a67YPHi3ByobmoKjjOda2qLJKFHtgPIF63dQa3f/lu7gyD+iXvYsGCbg9YP3gUPPRReoIXi8MOD5Hr11dDQEFwJ7sUXg665P/wh2KZfPxg3LhiTGD8+SMKZuGZ1mJqaNJ4godLXjQRSvTJWwu6gtj8XbWmBJUuYNe4pSoo/OOCpkt77mXVvHyTDhgwJuph++tPginQbNgSXJ21tds2YASefHPTTn3NOcBnRV16BXbuyHfnBGhuVFCRcycxwS/cGnAu8DawCZsR5/lDgV5Hn/wqUd/Sa6Y8zzw4AAAfbSURBVMxoDvvqW+7tzRze7/7SS+6zZrmfc457v37RJ+cMnu5lfRrc2O9lw/bnfl2eXPXuu+7z5gVF5kaM+PDDKypy//jH3SdOdP/mN4N/AEuXujc3Zy/W005zP/PM7L2/5CySnNFsHtKvM8ysGPg78GmgHlgMTHb35THbfAkY6e7XmtllwIXuPqm9162urvbaFGa1tu3WgWAMt70B2vLy+F07ZWXBF8uDuAf7rD/4J6NlrGMt5cHCiBHBzyhPOy24lZYmfRzShRoagtnUdXXBhLlly4IJhK1jEEVFwVjFiBFw/PHB/YgRcOyx0Lt3MBAclhNOCAbPf/e78N5D8pKZLXH36g63CzEpnAzc7u7nRJa/CeDu343Z5unINq+aWQ/gXWCItxNUqkkh4Qm+xzusPXZC3H2Klr9FvAogxn72DzkyODns3fvh/b591DCZaTx0wIzjkqJdzD73d0yZ1jfoux40KOm4pZvZsydIDMuWfZgo2iaLVkVF0KNHcCsubv9xUVFqSWTlSrj88mBSo0gKkk0KYQ40DwX+GbNcD5yUaBt3bzGzrcAg4L3YjcxsGjANYFhHM7XaSPgrn5Z/Cb7lxTFs7RbWNQ85eH3f9+Hii4PByNb/3JHHU3r2hLeeZeYzZ7K+qR/DSp1Z3+3NFP08KD8ccsiHLYJYscli1apguaUluO3bd/DjtutS/ZnsiBEwdWrmjkukjTCTQryvP21bAMlsg7vPBmZD0FJIJYiEv/IpKwomP8UxK0GX06yfDoYpP0n4XlMit0CIXQjSfSRKFiI5KsxfH9UDR8UslwIbEm0T6T4aALyfySDSmQWsSWIiUqjCTAqLgWPMbLiZHQJcBsxvs8184IrI40uA/9feeEI60j3Ba5KYiBSi0LqPImMENwBPA8XAw+6+zMzuIPhp1HzgZ8CjZraKoIVwWRixTJmik7qISDJCndHs7guBhW3W3Rrz+APg0jBjEBGR5GlGs4iIRCkpiIhIlJKCiIhEKSmIiEhUaGUuwmJmDUCc6WhJGUyb2dIFppCPv5CPHQr7+HXsgTJ3P7hUQxs5lxQ6w8xqk6n9ka8K+fgL+dihsI9fx57asav7SEREopQUREQkqtCSwuxsB5BlhXz8hXzsUNjHr2NPQUGNKYiISPsKraUgIiLtUFIQEZGogkkKZnaumb1tZqvMbEa24+lKZrbWzN4yszfMLPlrmeYoM3vYzDab2d9i1h1uZs+Y2crI/cBsxhiWBMd+u5m9E/n83zCz87MZY1jM7Cgze97MVpjZMjObHllfKJ99ouNP6fMviDEFMysG/g58muDCPouBye6+PKuBdREzWwtUu3tBTOAxs9OBHcD/uHtFZN2dwPvu/r3Il4KB7v7v2YwzDAmO/XZgh7vflc3YwmZm/wL8i7svNbN+wBLg88CVFMZnn+j4v0AKn3+htBTGAqvcfbW77wHmAhdkOSYJibu/xMFX8LsAeCTy+BGC/yx5J8GxFwR33+juSyOPtwMrCK4DXyiffaLjT0mhJIWhwD9jlutJ44+Vwxz4o5ktMbNp2Q4mSz7i7hsh+M8DHJHleLraDWb2ZqR7KS+7T2KZWTkwGvgrBfjZtzl+SOHzL5SkYHHW5X+/2YdOdfcq4Dzg+kgXgxSOnwBHA6OAjcDd2Q0nXGbWF/gt8GV335bteLpanONP6fMvlKRQDxwVs1wKbMhSLF3O3TdE7jcDjxN0pxWaTZE+19a+181ZjqfLuPsmd9/n7vuBh8jjz9/MehKcEGvc/XeR1QXz2cc7/lQ//0JJCouBY8xsuJkdQnAt6PlZjqlLmFmfyKATZtYHmAD8rf298tJ84IrI4yuA32cxli7VekKMuJA8/fzNzAiu+77C3X8Y81RBfPaJjj/Vz78gfn0EEPkZ1r1AMfCwu8/Kckhdwsw+RtA6gOCa3L/M92M3s8eAMwjKBm8CbgOeAOYBw4D1wKXunncDsgmO/QyCrgMH1gL/p7WPPZ+Y2TjgT8BbwP7I6m8R9KsXwmef6Pgnk8LnXzBJQUREOlYo3UciIpIEJQUREYlSUhARkSglBRERiVJSEBGRKCUFkQgz2xdTSfKNTFbTNbPy2MqlIt1Vj2wHINKN7HL3UdkOQiSb1FIQ6UDkehTfN7PXIrePR9aXmdlzkUJjz5nZsMj6j5jZ42ZWF7mdEnmpYjN7KFLr/o9m1juy/U1mtjzyOnOzdJgigJKCSKzebbqPJsU8t83dxwL3E8yMJ/L4f9x9JFAD3BdZfx/wortXAlXAssj6Y4AH3H0E0ARcHFk/AxgdeZ1rwzo4kWRoRrNIhJntcPe+cdavBT7l7qsjBcfedfdBZvYewUVN9kbWb3T3wWbWAJS6++6Y1ygHnnH3YyLL/w70dPdvm9kiggvjPAE84e47Qj5UkYTUUhBJjid4nGibeHbHPN7Hh2N6nwEeAMYAS8xMY32SNUoKIsmZFHP/auTxKwQVdwGmAC9HHj8HXAfBpWDNrH+iFzWzIuAod38e+AZwGHBQa0Wkq+gbiciHepvZGzHLi9y99Weph5rZXwm+SE2OrLsJeNjMvg40AFMj66cDs83saoIWwXUEFzeJpxiYY2YDCC4GdY+7N2XsiERSpDEFkQ5ExhSq3f29bMciEjZ1H4mISJRaCiIiEqWWgoiIRCkpiIhIlJKCiIhEKSmIiEiUkoKIiET9fxcq+o4s727nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_Complete_ReRun.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,343,146\n",
      "Trainable params: 1,342,698\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model50K = Sequential()\n",
    "model50K.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model50K.add(Activation('relu'))\n",
    "\n",
    "model50K.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model50K.add(BatchNormalization())\n",
    "model50K.add(Activation('relu'))\n",
    "\n",
    "model50K.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model50K.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model50K.add(Activation('relu'))\n",
    "\n",
    "model50K.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model50K.add(BatchNormalization())\n",
    "model50K.add(Activation('relu'))\n",
    "\n",
    "model50K.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model50K.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model50K.add(Activation('relu'))\n",
    "\n",
    "model50K.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model50K.add(BatchNormalization())\n",
    "model50K.add(Activation('relu'))\n",
    "\n",
    "model50K.add(MaxPooling2D((3, 3)))\n",
    "\n",
    "model50K.add(Flatten())\n",
    "\n",
    "model50K.add(Dropout(0.3))\n",
    "model50K.add(Dense(1024, activation='relu'))\n",
    "\n",
    "model50K.add(Dropout(0.5))\n",
    "model50K.add(Dense(512, activation='relu'))\n",
    "\n",
    "model50K.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model50K.summary()\n",
    "\n",
    "learning_rate = 1E-5 \n",
    "\n",
    "model50K.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(learning_rate=learning_rate, momentum=0.1),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 12s 239us/step - loss: 5.4893e-04 - acc: 0.0929\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 5.0097e-04 - acc: 0.1191\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 5.6602e-04 - acc: 0.1110\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 5.5266e-04 - acc: 0.1014\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 5.8037e-04 - acc: 0.0940\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 6.3392e-04 - acc: 0.0921\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 5.9725e-04 - acc: 0.0943\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 6.5988e-04 - acc: 0.0948\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 7.4377e-04 - acc: 0.0959\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 7.7202e-04 - acc: 0.0997\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.0015 - acc: 0.1003\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.0027 - acc: 0.1000\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: nan - acc: 0.2128s - loss: nan - a\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: nan - acc: 0.9998\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: nan - acc: 0.9998\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: nan - acc: 0.9998\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: nan - acc: 0.9998\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: nan - acc: 0.9998\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: nan - acc: 0.9998\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: nan - acc: 0.9998\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: nan - acc: 0.9998\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: nan - acc: 0.9998\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: nan - acc: 0.9998\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: nan - acc: 0.9998\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: nan - acc: 0.9998\n"
     ]
    }
   ],
   "source": [
    "My_x_train = x_train/255.0 \n",
    "history = model50K.fit(My_x_train, y_train_vec, batch_size=64, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 163us/step\n",
      "loss = nan\n",
      "accuracy = 0.9991000294685364\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model50K.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
