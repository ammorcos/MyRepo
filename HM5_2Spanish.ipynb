{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 5: Build a seq2seq model for machine translation.\n",
    "\n",
    "### Name: [Amir Morcos]\n",
    "\n",
    "### Task: Translate English to [Spanish]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read and run my code.\n",
    "2. Complete the code in Section 1.1 and Section 4.2.\n",
    "\n",
    "    * Translation **English** to **German** is not acceptable!!! Try another pair of languages.\n",
    "    \n",
    "3. **Make improvements.** Directly modify the code in Section 3. Do at least one of the two. By doing both correctly, you will get up to 1 bonus score to the total.\n",
    "\n",
    "    * Bi-LSTM instead of LSTM.\n",
    "        \n",
    "    * Attention. (You are allowed to use existing code.)\n",
    "    \n",
    "4. Evaluate the translation using the BLEU score. \n",
    "\n",
    "    * Optional. Up to 1 bonus scores to the total.\n",
    "    \n",
    "5. Convert the notebook to .HTML file. \n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "\n",
    "6. Put the .HTML file in your Google Drive, Dropbox, or Github repo.  (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "7. Submit the link to the HTML file to Canvas.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hint: \n",
    "\n",
    "To implement ```Bi-LSTM```, you will need the following code to build the encoder. Do NOT use Bi-LSTM for the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.layers import Bidirectional, Concatenate\n",
    "\n",
    "#encoder_bilstm = Bidirectional(LSTM(latent_dim, return_state=True, \n",
    "#                                  dropout=0.5, name='encoder_lstm'))\n",
    "#_, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_inputs)\n",
    "\n",
    "#state_h = Concatenate()([forward_h, backward_h])\n",
    "#state_c = Concatenate()([forward_c, backward_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "1. Download data (e.g., \"deu-eng.zip\") from http://www.manythings.org/anki/\n",
    "2. Unzip the .ZIP file.\n",
    "3. Put the .TXT file (e.g., \"deu.txt\") in the directory \"./Data/\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load and clean text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from unicodedata import normalize\n",
    "import numpy\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "\n",
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in  lines]\n",
    "    return pairs\n",
    "\n",
    "def clean_data(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for pair in lines:\n",
    "        clean_pair = list()\n",
    "        for line in pair:\n",
    "            # normalize unicode characters\n",
    "            line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "            line = line.decode('UTF-8')\n",
    "            # tokenize on white space\n",
    "            line = line.split()\n",
    "            # convert to lowercase\n",
    "            line = [word.lower() for word in line]\n",
    "            # remove punctuation from each token\n",
    "            line = [word.translate(table) for word in line]\n",
    "            # remove non-printable chars form each token\n",
    "            line = [re_print.sub('', w) for w in line]\n",
    "            # remove tokens with numbers in them\n",
    "            line = [word for word in line if word.isalpha()]\n",
    "            # store as string\n",
    "            clean_pair.append(' '.join(line))\n",
    "        cleaned.append(clean_pair)\n",
    "    return numpy.array(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill the following blanks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g., filename = 'Data/deu.txt'\n",
    "filename = 'Data/spa.txt'\n",
    "\n",
    "# e.g., n_train = 20000\n",
    "\n",
    "n_train = 35000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "TestSize = 100\n",
    "doc = load_doc(filename)\n",
    "\n",
    "# split into Language1-Language2 pairs\n",
    "pairs = to_pairs(doc)\n",
    "rand_indices = numpy.random.permutation(n_train+TestSize)\n",
    "\n",
    "\n",
    "# clean sentences\n",
    "clean_pairs = clean_data(pairs)[rand_indices[0:n_train], :]\n",
    "Test_pairs = clean_data(pairs)[rand_indices[n_train:n_train+TestSize], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[none of us want that] => [nadie de nosotros quiere eso]\n",
      "[is anybody here] => [hay alguien aqui]\n",
      "[i had a stroke] => [tuve un golpe]\n",
      "[look again] => [miren de nuevo]\n",
      "[im not good at this] => [esto no se me da bien]\n",
      "[does it taste okay] => [sabe bien]\n",
      "[im not even canadian] => [incluso no soy canadiense]\n",
      "[has something happened] => [ha sucedido algo]\n",
      "[what are you reading] => [que estas leyendo]\n",
      "[that is not true] => [eso no es verdad]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3000, 3010):\n",
    "    print('[' + clean_pairs[i, 0] + '] => [' + clean_pairs[i, 1] + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of input_texts:  (35000,)\n",
      "Length of target_texts: (35000,)\n"
     ]
    }
   ],
   "source": [
    "input_texts = clean_pairs[:, 0]\n",
    "target_texts = ['\\t' + text + '\\n' for text in clean_pairs[:, 1]]\n",
    "\n",
    "print('Length of input_texts:  ' + str(input_texts.shape))\n",
    "print('Length of target_texts: ' + str(input_texts.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length of input  sentences: 22\n",
      "max length of target sentences: 68\n"
     ]
    }
   ],
   "source": [
    "max_encoder_seq_length = max(len(line) for line in input_texts)\n",
    "max_decoder_seq_length = max(len(line) for line in target_texts)\n",
    "\n",
    "print('max length of input  sentences: %d' % (max_encoder_seq_length))\n",
    "print('max length of target sentences: %d' % (max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** To this end, you have two lists of sentences: input_texts and target_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text processing\n",
    "\n",
    "### 2.1. Convert texts to sequences\n",
    "\n",
    "- Input: A list of $n$ sentences (with max length $t$).\n",
    "- It is represented by a $n\\times t$ matrix after the tokenization and zero-padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of encoder_input_seq: (35000, 22)\n",
      "shape of input_token_index: 27\n",
      "shape of decoder_input_seq: (35000, 68)\n",
      "shape of target_token_index: 29\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# encode and pad sequences\n",
    "def text2sequences(max_len, lines):\n",
    "    tokenizer = Tokenizer(char_level=True, filters='')\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    seqs = tokenizer.texts_to_sequences(lines)\n",
    "    seqs_pad = pad_sequences(seqs, maxlen=max_len, padding='post')\n",
    "    return seqs_pad, tokenizer.word_index\n",
    "\n",
    "\n",
    "encoder_input_seq, input_token_index = text2sequences(max_encoder_seq_length, \n",
    "                                                      input_texts)\n",
    "decoder_input_seq, target_token_index = text2sequences(max_decoder_seq_length, \n",
    "                                                       target_texts)\n",
    "\n",
    "print('shape of encoder_input_seq: ' + str(encoder_input_seq.shape))\n",
    "print('shape of input_token_index: ' + str(len(input_token_index)))\n",
    "print('shape of decoder_input_seq: ' + str(decoder_input_seq.shape))\n",
    "print('shape of target_token_index: ' + str(len(target_token_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_encoder_tokens: 28\n",
      "num_decoder_tokens: 30\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens = len(input_token_index) + 1\n",
    "num_decoder_tokens = len(target_token_index) + 1\n",
    "\n",
    "print('num_encoder_tokens: ' + str(num_encoder_tokens))\n",
    "print('num_decoder_tokens: ' + str(num_decoder_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, 'e': 2, 't': 3, 'o': 4, 'i': 5, 'a': 6, 's': 7, 'h': 8, 'n': 9, 'r': 10, 'l': 11, 'd': 12, 'm': 13, 'y': 14, 'u': 15, 'w': 16, 'g': 17, 'c': 18, 'p': 19, 'k': 20, 'b': 21, 'f': 22, 'v': 23, 'j': 24, 'x': 25, 'z': 26, 'q': 27}\n"
     ]
    }
   ],
   "source": [
    "print(input_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, 'e': 2, 'a': 3, 'o': 4, 's': 5, 'n': 6, '\\t': 7, '\\n': 8, 't': 9, 'r': 10, 'i': 11, 'l': 12, 'u': 13, 'm': 14, 'd': 15, 'c': 16, 'p': 17, 'b': 18, 'v': 19, 'g': 20, 'h': 21, 'q': 22, 'y': 23, 'f': 24, 'j': 25, 'z': 26, 'x': 27, 'k': 28, 'w': 29}\n"
     ]
    }
   ],
   "source": [
    "print(target_token_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** To this end, the input language and target language texts are converted to 2 matrices. \n",
    "\n",
    "- Their number of rows are both n_train.\n",
    "- Their number of columns are respective max_encoder_seq_length and max_decoder_seq_length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The followings print a sentence and its representation as a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\tparece interesante\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 17,  3, 10,  2, 16,  2,  1, 11,  6,  9,  2, 10,  2,  5,  3,  6,\n",
       "        9,  2,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_seq[100, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. One-hot encode\n",
    "\n",
    "- Input: A list of $n$ sentences (with max length $t$).\n",
    "- It is represented by a $n\\times t$ matrix after the tokenization and zero-padding.\n",
    "- It is represented by a $n\\times t \\times v$ tensor ($t$ is the number of unique chars) after the one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 22, 28)\n",
      "(35000, 68, 30)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# one hot encode target sequence\n",
    "def onehot_encode(sequences, max_len, vocab_size):\n",
    "    n = len(sequences)\n",
    "    data = numpy.zeros((n, max_len, vocab_size))\n",
    "    for i in range(n):\n",
    "        data[i, :, :] = to_categorical(sequences[i], num_classes=vocab_size)\n",
    "    return data\n",
    "\n",
    "encoder_input_data = onehot_encode(encoder_input_seq, max_encoder_seq_length, num_encoder_tokens)\n",
    "decoder_input_data = onehot_encode(decoder_input_seq, max_decoder_seq_length, num_decoder_tokens)\n",
    "\n",
    "decoder_target_seq = numpy.zeros(decoder_input_seq.shape)\n",
    "decoder_target_seq[:, 0:-1] = decoder_input_seq[:, 1:]\n",
    "decoder_target_data = onehot_encode(decoder_target_seq, \n",
    "                                    max_decoder_seq_length, \n",
    "                                    num_decoder_tokens)\n",
    "\n",
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the networks (for training)\n",
    "\n",
    "- Build encoder, decoder, and connect the two modules to get \"model\". \n",
    "\n",
    "- Fit the model on the bilingual data to train the parameters in the encoder and decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Encoder network\n",
    "\n",
    "- Input:  one-hot encode of the input language\n",
    "\n",
    "- Return: \n",
    "\n",
    "    -- output (all the hidden states   $h_1, \\cdots , h_t$) are always discarded\n",
    "    \n",
    "    -- the final hidden state  $h_t$\n",
    "    \n",
    "    -- the final conveyor belt $c_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Bidirectional, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "latent_dim = 128*4 #was 256\n",
    "\n",
    "# inputs of the encoder network\n",
    "\n",
    "encoder_inputs = Input(shape=(None,num_encoder_tokens), name='encoder_inputs')\n",
    "#if I need to go back to a single layer, return state NOT sequences\n",
    "\n",
    "encoder_bilstm1 = Bidirectional(LSTM(latent_dim, return_sequences=True, \n",
    "                                     dropout=0.25, name='encoder_bilstm1'))(encoder_inputs)\n",
    "\n",
    "_, forward_h, forward_c, backward_h, backward_c  = Bidirectional(LSTM(latent_dim, return_state=True, dropout=0.25,\n",
    "                                                                      name='encoder_bilstm2'))(encoder_bilstm1)\n",
    "state_Eh = Concatenate()([forward_h, backward_h])\n",
    "state_Ec = Concatenate()([forward_c, backward_c])\n",
    "\n",
    "#encoder_states = [state_Eh, state_Ec] # encoder_output discarded\n",
    "\n",
    "# build the encoder network model\n",
    "encoder_model = Model(inputs=encoder_inputs, \n",
    "                      outputs=[state_Eh, state_Ec],\n",
    "                      name='encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After struggling with adding a 2nd layer to the decoder, I found this link and was able to better follow how the model is constructed\n",
    "https://github.com/google/seq2seq/issues/320"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a summary and save the encoder network structure to \"./encoder.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     (None, None, 28)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 1024)   2215936     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 1024), (None 6295552     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1024)         0           bidirectional_2[0][2]            \n",
      "                                                                 bidirectional_2[0][4]            \n",
      "==================================================================================================\n",
      "Total params: 8,511,488\n",
      "Trainable params: 8,511,488\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "SVG(model_to_dot(encoder_model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(\n",
    "    model=encoder_model, show_shapes=False,\n",
    "    to_file='encoder.pdf'\n",
    ")\n",
    "\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Decoder network\n",
    "\n",
    "- Inputs:  \n",
    "\n",
    "    -- one-hot encode of the target language\n",
    "    \n",
    "    -- The initial hidden state $h_t$ \n",
    "    \n",
    "    -- The initial conveyor belt $c_t$ \n",
    "\n",
    "- Return: \n",
    "\n",
    "    -- output (all the hidden states) $h_1, \\cdots , h_t$\n",
    "\n",
    "    -- the final hidden state  $h_t$ (discarded in the training and used in the prediction)\n",
    "    \n",
    "    -- the final conveyor belt $c_t$ (discarded in the training and used in the prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# inputs of the decoder network\n",
    "decoder_input_h = Input(shape=(latent_dim*2,), name='decoder_input_h')#we ad *2 because we made the encoder bidirectional\n",
    "decoder_input_c = Input(shape=(latent_dim*2,), name='decoder_input_c')\n",
    "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "encoder_state = [decoder_input_h,decoder_input_c]\n",
    "\n",
    "# set the LSTM layer\n",
    "decoder_lstm1_layer = LSTM(latent_dim*2, return_sequences=True, \n",
    "                                    return_state=True, dropout=0.25, name='decoder_lstm1')\n",
    "decoder_lstm1_layer_output, state_hd1,state_cd1= decoder_lstm1_layer(decoder_input_x, initial_state=encoder_state)\n",
    "\n",
    "\n",
    "#decoder_lstm2_layer = LSTM(latent_dim*2,return_sequences=True,  \n",
    "#                                    return_state=True, dropout=0.25, name='decoder_lstm2')\n",
    "#decoder_lstm2_layer_output, state_hd2,state_cd2 = decoder_lstm2_layer(decoder_lstm1_layer_output)\n",
    "                                                #May need to set initial state \n",
    "\n",
    "#Skip_A_Few = Concatenate()([decoder_lstm2_layer_output, decoder_input_x])\n",
    "\n",
    "#Fully_Connected1 = Dense(512, activation='relu', name='Fully_Connected1')\n",
    "#Fully_Connected_Out1 = Fully_Connected1(decoder_lstm2_layer_output) \n",
    "\n",
    "#Fully_Connected2 = Dense(512, activation='relu', name='Fully_Connected2')\n",
    "#Fully_Connected_Out2 = Fully_Connected2(Fully_Connected_Out1) \n",
    "\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_lstm1_layer_output)\n",
    "\n",
    "# build the decoder network model\n",
    "decoder_model = Model(inputs=[decoder_input_x, decoder_input_h, decoder_input_c],\n",
    "                      outputs=[decoder_outputs, state_hd1, state_cd1],\n",
    "                      #outputs=[decoder_outputs],\n",
    "                      name='decoder_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a summary and save the encoder network structure to \"./decoder.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input_x (InputLayer)    (None, None, 30)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_h (InputLayer)    (None, 1024)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_c (InputLayer)    (None, 1024)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm1 (LSTM)            [(None, None, 1024), 4321280     decoder_input_x[0][0]            \n",
      "                                                                 decoder_input_h[0][0]            \n",
      "                                                                 decoder_input_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 30)     30750       decoder_lstm1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,352,030\n",
      "Trainable params: 4,352,030\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "SVG(model_to_dot(decoder_model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(\n",
    "    model=decoder_model, show_shapes=False,\n",
    "    to_file='decoder.pdf'\n",
    ")\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Connect the encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layers\n",
    "encoder_input_x = Input(shape=(None, num_encoder_tokens), name='encoder_input_x')\n",
    "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "# connect encoder to decoder\n",
    "encoder_final_states_h,encoder_final_states_c  = encoder_model([encoder_input_x])\n",
    "decoder_pred,_,_ = decoder_model([decoder_input_x,encoder_final_states_h,encoder_final_states_c])\n",
    "\n",
    "\n",
    "model = Model(inputs=[encoder_input_x, decoder_input_x], \n",
    "              outputs=decoder_pred, \n",
    "              name='model_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_training\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_x (InputLayer)    (None, None, 28)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_x (InputLayer)    (None, None, 30)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 1024), (None 8511488     encoder_input_x[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_model (Model)           [(None, None, 30), ( 4352030     decoder_input_x[0][0]            \n",
      "                                                                 encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "==================================================================================================\n",
      "Total params: 12,863,518\n",
      "Trainable params: 12,863,518\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(\n",
    "    model=model, show_shapes\n",
    "    =False,\n",
    "    to_file='model_training.pdf'\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Fit the model on the bilingual dataset\n",
    "\n",
    "- encoder_input_data: one-hot encode of the input language\n",
    "\n",
    "- decoder_input_data: one-hot encode of the input language\n",
    "\n",
    "- decoder_target_data: labels (left shift of decoder_input_data)\n",
    "\n",
    "- tune the hyper-parameters\n",
    "\n",
    "- stop when the validation loss stop decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of encoder_input_data(35000, 22, 28)\n",
      "shape of decoder_input_data(35000, 68, 30)\n",
      "shape of decoder_target_data(35000, 68, 30)\n"
     ]
    }
   ],
   "source": [
    "print('shape of encoder_input_data' + str(encoder_input_data.shape))\n",
    "print('shape of decoder_input_data' + str(decoder_input_data.shape))\n",
    "print('shape of decoder_target_data' + str(decoder_target_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "temperature = 0.5\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = numpy.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # this line of code is greedy selection\n",
    "        # try to use multinomial sampling instead (with temperature)\n",
    "        output_tokens = output_tokens ** (1 / temperature)        \n",
    "        output_tokens = output_tokens / numpy.sum(output_tokens)\n",
    "     \n",
    "        sampled_token_index = numpy.argmax(output_tokens[0, -1, :])\n",
    "        if(sampled_token_index == 0):      \n",
    "            sampled_token_index=target_token_index['\\n']#replacing 0 with end of string\n",
    "            print(\"Encountered Zero sampled_token_index\")\n",
    "\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "\n",
    "        target_seq = numpy.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testThething(input_sentence):\n",
    "    input_sequence = [input_token_index[n] for n in list(input_sentence.lower())]\n",
    "    while len(input_sequence)<max_encoder_seq_length:\n",
    "        input_sequence.append(0)\n",
    "        \n",
    "    input_x = onehot_encode(numpy.array(input_sequence), max_encoder_seq_length, num_encoder_tokens)\n",
    "    return decode_sequence([[input_x[:,0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 179s 6ms/step - loss: 0.7563 - val_loss: 0.5458\n",
      "Epoch  =  1\n",
      "esta esta\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 176s 6ms/step - loss: 0.5511 - val_loss: 0.4544\n",
      "Epoch  =  2\n",
      "cracia\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 176s 6ms/step - loss: 0.4820 - val_loss: 0.3954\n",
      "Epoch  =  3\n",
      "gracias\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 176s 6ms/step - loss: 0.4333 - val_loss: 0.3557\n",
      "Epoch  =  4\n",
      "gracias por mi\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 174s 6ms/step - loss: 0.3936 - val_loss: 0.3256\n",
      "Epoch  =  5\n",
      "gracias por ti\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 174s 6ms/step - loss: 0.3621 - val_loss: 0.3021\n",
      "Epoch  =  6\n",
      "gracias por vi\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 176s 6ms/step - loss: 0.3358 - val_loss: 0.2851\n",
      "Epoch  =  7\n",
      "gracias por ti\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 177s 6ms/step - loss: 0.3118 - val_loss: 0.2728\n",
      "Epoch  =  8\n",
      "gracias por ti\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 176s 6ms/step - loss: 0.2916 - val_loss: 0.2609\n",
      "Epoch  =  9\n",
      "gracias\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 177s 6ms/step - loss: 0.2730 - val_loss: 0.2527\n",
      "Epoch  =  10\n",
      "gracias por ti\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 176s 6ms/step - loss: 0.2583 - val_loss: 0.2474\n",
      "Epoch  =  11\n",
      "gracias por ti\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 176s 6ms/step - loss: 0.2419 - val_loss: 0.2433\n",
      "Epoch  =  12\n",
      "gracias a ti\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 174s 6ms/step - loss: 0.2285 - val_loss: 0.2395\n",
      "Epoch  =  13\n",
      "gracias\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 176s 6ms/step - loss: 0.2155 - val_loss: 0.2363\n",
      "Epoch  =  14\n",
      "gracias\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 176s 6ms/step - loss: 0.2040 - val_loss: 0.2339\n",
      "Epoch  =  15\n",
      "gracias por to\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 176s 6ms/step - loss: 0.1929 - val_loss: 0.2342\n",
      "Epoch  =  16\n",
      "gracias\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 176s 6ms/step - loss: 0.1826 - val_loss: 0.2350\n",
      "Epoch  =  17\n",
      "gracias\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 176s 6ms/step - loss: 0.1733 - val_loss: 0.2342\n",
      "Epoch  =  18\n",
      "gracias\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 176s 6ms/step - loss: 0.1658 - val_loss: 0.2357\n",
      "Epoch  =  19\n",
      "gracias a ti\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 176s 6ms/step - loss: 0.1569 - val_loss: 0.2357\n",
      "Epoch  =  20\n",
      "gracias a ti\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 176s 6ms/step - loss: 0.1505 - val_loss: 0.2370\n",
      "Epoch  =  21\n",
      "gracias\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 175s 6ms/step - loss: 0.1446 - val_loss: 0.2394\n",
      "Epoch  =  22\n",
      "gracias\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 173s 6ms/step - loss: 0.1372 - val_loss: 0.2412\n",
      "Epoch  =  23\n",
      "gracias\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 174s 6ms/step - loss: 0.1312 - val_loss: 0.2446\n",
      "Epoch  =  24\n",
      "gracias\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/1\n",
      "28000/28000 [==============================] - 175s 6ms/step - loss: 0.1261 - val_loss: 0.2465\n",
      "Epoch  =  25\n",
      "gracias\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "model.compile(optimizer=optimizers.rmsprop(learning_rate =0.0005 ), loss='categorical_crossentropy')\n",
    "EPOCHS = 25\n",
    "#model.fit([encoder_input_data, decoder_input_data],  # training data\n",
    "#          decoder_target_data,                       # labels (left shift of the target sequences)\n",
    "#          batch_size=64, epochs=20, validation_split=0.2)\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    model.fit([encoder_input_data, decoder_input_data],  # training data\n",
    "          decoder_target_data,                       # labels (left shift of the target sequences)\n",
    "          batch_size=32, validation_split=0.2)\n",
    "\n",
    "    print(\"Epoch  = \",i+1)\n",
    "    print(testThething('Thank you'))\n",
    "    \n",
    "\n",
    "model.save('seq2seq_2b.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make predictions\n",
    "\n",
    "\n",
    "### 4.1. Translate English to Spanish\n",
    "\n",
    "1. Encoder read a sentence (source language) and output its final states, $h_t$ and $c_t$.\n",
    "2. Take the [star] sign \"\\t\" and the final state $h_t$ and $c_t$ as input and run the decoder.\n",
    "3. Get the new states and predicted probability distribution.\n",
    "4. sample a char from the predicted probability distribution\n",
    "5. take the sampled char and the new states as input and repeat the process (stop if reach the [stop] sign \"\\n\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100\n",
      "English:        i go to school by bus\n",
      "Spanish (true):  voy a la escuela en colectivo\n",
      "Spanish (pred):  voy a la escuela en colectivo\n",
      "2101\n",
      "English:        red wine please\n",
      "Spanish (true):  vino tinto por favor\n",
      "Spanish (pred):  vino tonto por favor\n",
      "2102\n",
      "English:        it wasnt planned\n",
      "Spanish (true):  no estaba planeado\n",
      "Spanish (pred):  no estaba llorando\n",
      "2103\n",
      "English:        i like potato salad\n",
      "Spanish (true):  me gusta la ensalada de patatas\n",
      "Spanish (pred):  me gusta la ensalada de latas\n",
      "2104\n",
      "English:        id say the same thing\n",
      "Spanish (true):  yo diria lo mismo\n",
      "Spanish (pred):  yo diria lo mismo\n",
      "2105\n",
      "English:        i guessed right\n",
      "Spanish (true):  lo adivine correctamente\n",
      "Spanish (pred):  aceste bien\n",
      "2106\n",
      "English:        tom won the bet\n",
      "Spanish (true):  tom gano la apuesta\n",
      "Spanish (pred):  tom gano la apuesta\n",
      "2107\n",
      "English:        she is a bad person\n",
      "Spanish (true):  ella es una mala persona\n",
      "Spanish (pred):  ella es una mala persona\n",
      "2108\n",
      "English:        look out\n",
      "Spanish (true):  cuidado\n",
      "Spanish (pred):  cuidado\n",
      "2109\n",
      "English:        do you like english\n",
      "Spanish (true):  les gusta el ingles\n",
      "Spanish (pred):  le gusta el ingles\n",
      "2110\n",
      "English:        he is just a kid\n",
      "Spanish (true):  solo es un nino\n",
      "Spanish (pred):  solo es un nino\n",
      "2111\n",
      "English:        heres some water\n",
      "Spanish (true):  aqui tienes un poco de agua\n",
      "Spanish (pred):  aqui hay un poco de agua\n",
      "2112\n",
      "English:        we depend on you\n",
      "Spanish (true):  dependemos de usted\n",
      "Spanish (pred):  dependemos de ti\n",
      "2113\n",
      "English:        seeing is believing\n",
      "Spanish (true):  ver es creer\n",
      "Spanish (pred):  ver para creer\n",
      "2114\n",
      "English:        its now\n",
      "Spanish (true):  son las dos y media ahora\n",
      "Spanish (pred):  ahora son las dos y media\n",
      "2115\n",
      "English:        write me something\n",
      "Spanish (true):  escribeme algo\n",
      "Spanish (pred):  escribeme algo\n",
      "2116\n",
      "English:        money does not smell\n",
      "Spanish (true):  el dinero no huele\n",
      "Spanish (pred):  el dinero no huele\n",
      "2117\n",
      "English:        tom has been trapped\n",
      "Spanish (true):  tom ha sido atrapado\n",
      "Spanish (pred):  tom ha sido atrapado\n",
      "2118\n",
      "English:        i know i packed it\n",
      "Spanish (true):  se que estaba ahi metido\n",
      "Spanish (pred):  se que lo me estara\n",
      "2119\n",
      "English:        are you kidding\n",
      "Spanish (true):  estas bromeando\n",
      "Spanish (pred):  estas bromeando\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(2100, 2120):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    \n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]    \n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(seq_index)\n",
    "    print('English:       ', input_texts[seq_index])\n",
    "    print('Spanish (true): ', target_texts[seq_index][1:-1])\n",
    "    print('Spanish (pred): ', decoded_sentence[0:-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Translate an English sentence to the target language\n",
    "\n",
    "1. Tokenization\n",
    "2. One-hot encode\n",
    "3. Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source sentence is: I love you\n",
      "translated sentence is: yo amo\n"
     ]
    }
   ],
   "source": [
    "input_sentence = 'I love you'\n",
    "\n",
    "translated_sentence = testThething(input_sentence)\n",
    "\n",
    "print('source sentence is: ' + input_sentence)\n",
    "print('translated sentence is: ' + translated_sentence[0:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the translation using BLEU score\n",
    "\n",
    "Reference: \n",
    "- https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
    "- https://en.wikipedia.org/wiki/BLEU\n",
    "\n",
    "\n",
    "**Hint:** \n",
    "\n",
    "- Randomly partition the dataset to training, validation, and test. \n",
    "\n",
    "- Evaluate the BLEU score using the test set. Report the average.\n",
    "\n",
    "- A reasonable BLEU score should be 0.1 ~ 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\.conda\\envs\\DeepLearning\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Amir\\.conda\\envs\\DeepLearning\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Amir\\.conda\\envs\\DeepLearning\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared:: ella fijo su mirada en mi ::to:: ella me suplio a mary\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ni siquiera le conozco ::to:: ainalla se conozco\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: que hincha pelotas ::to:: que incordio\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: continuaron corriendo ::to:: siguieron corriendo\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: amo a mis amigas ::to:: amo a mis amigas\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: eso era todo lo que necesitaba ::to:: eso fue nueca lo piento\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: vamos a cerrar temprano ::to:: estamos pintando para madar\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: mira de nuevo ::to:: mira atras\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom lo hizo ::to:: tom lo hizo\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: no puedo ver a tom ::to:: no puedo ver a tom\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: tom fue el que intervino ::to:: tom intirvino\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: soy el abuelo de tomas ::to:: soy el abuglado de tom\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: no me digas ::to:: no dicertes\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: donde esta el perro ::to:: donde esta el perro\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: nos ensena frances ::to:: ella nos ensena frances\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: puedo usar el bano ::to:: puedo usar el bano\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: come algo ::to:: hame algo de hambre\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: una promesa es una promesa ::to:: promesas son promesas\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ensename como hacerlo ::to:: muestrame como hacer eso\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: no puedo esperar para siempre ::to:: no puedo esperar mas\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tengo la llave ::to:: tengo la llave\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: consiguio un nuevo trabajo ::to:: el comio un buen trabajo\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: poneoslo ::to:: pontelo a el\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom tiene sed ::to:: tom tiene sed\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: yo lo escribi ::to:: lo descrbre\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: dame tu opinion ::to:: dime tu opinion\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: hagamos mas ::to:: vayamos a mary\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: donde esta tu bebe ::to:: donde esta tu bolsa\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: creo que es demasiado tarde ::to:: yo pienso que es mey sardo\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: me he dejado la puerta abierta ::to:: deje la puerta abierta\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tomas era mayor ::to:: tom estaba viejo\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tomas es imparable ::to:: tom es incolprete\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: el ya se habia ido ::to:: ya ya hamos mar\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: mi hermana tiene un trabajo ::to:: mi hermana es buena palabra\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: estas saturado de trabajo ::to:: estas muy cansada\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: solo estoy ayudando ::to:: estoy acurado de salir\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: sus padres lo odian ::to:: sus padres le entanaran\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: a tom le gustan los tomates ::to:: a tom le gusta mananas\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: por favor escucha ::to:: por favor escucha\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: debo destruirte ::to:: tengo que destauirte\n",
      " ::BLEU Score = 0.000000\n",
      "Encountered Zero sampled_token_index\n",
      "Compared:: le pedi ayuda ::to:: pedi comparos de sur \n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: a el le gusta mucho viajar ::to:: a el le encanta la vistar\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom se sento en su escritorio ::to:: tomas se secto en su hija\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: conozco a los de tu tipo ::to:: se que tienes esto\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: alguien esta comiendo ::to:: alguien esta comiendo\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: es dificil de justificar ::to:: es dificil de complacer\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: quede inconsciente ::to:: le descabe\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: acercate mas a mi ::to:: vuelve a casa conmigo\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: el se tino el pelo de negro ::to:: el de dusce es es espicio\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: los paraguas se venden bien ::to:: luego una memana liere\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tome una decision ::to:: me he decidido\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: es su coche ::to:: ese es el coche\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: creo que le gustas ::to:: creo que les me gusta\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: fallamos ::to:: nos repanamos\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: hazlo rapido ::to:: haz que sucede\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: su auto es un ford ::to:: su auto es un genio\n",
      " ::BLEU Score = 0.668740\n",
      "Compared:: tom esta en casa ::to:: esta tom en casa\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: mi nombre es tom ::to:: me llamo tom\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom tiene la llave ::to:: tom tiene la llave\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: odio a los insectos ::to:: odio las sopaces\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: el camion se ha ido ::to:: el tren esta solo\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: os gustan las naranjas ::to:: le gustan las naranjas\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: no me amenaces ::to:: no me molestes\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: el esta nadando ahora ::to:: el esta audando ahora\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: las fiestas son divertidas ::to:: los precios son lirdos\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: ven a nosotros ::to:: ven a esto\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: quien se comio la tarta ::to:: quien ha roto el arti\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: le acompanare ::to:: le mostrare la salida\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom casi fue despedido ::to:: tom casi se aligo\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: suspire ::to:: me tiero\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tomas quiere un auto ::to:: tom quiere al carro\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: eres mi enemigo ::to:: sos mi enemiga\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: no es caro ::to:: no es extrano\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: adivina donde estuve ::to:: adivinen donde estaba\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: viene una tormenta de arena ::to:: deja de que venga en elguelimo\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: no puedo hacerlo ::to:: no puedo hacerlo\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: tom lo hizo por si solo ::to:: tom lo hizo a dor su medera\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom nunca conocio a mary ::to:: tom nunca conto a mary\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: sabes quien soy ::to:: sabes como quieres\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom no come mucho ::to:: tom no come malia\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom le debe mucho a mary ::to:: tom de puede mucho dimaro\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: me siento aliviado ::to:: estoy listo\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: vivo en una gran ciudad ::to:: vivo en una chica guana\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: vas con retraso ::to:: vas tarde\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: pareces sorprendida ::to:: pareces sorprendido\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: no son mis libros ::to:: no han michos\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: que saben ustedes ::to:: que sabes\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: paraos aqui ::to:: detente aqui\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom es conservador ::to:: tom es cometivo\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: cual es la solucion ::to:: que ecula con esta puerta\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom esta hipnotizado ::to:: tom esta despruido\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: me puedo sentar a tu lado ::to:: puedo sentarme a su lado\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: a tom le debo un favor ::to:: le debo un favor a tom\n",
      " ::BLEU Score = 0.604275\n",
      "Compared:: te perturban las serpientes ::to:: te compresupan a su padre\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: comes carne ::to:: comeis carne\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: aqui viene el camarero ::to:: aqui viene el tren\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: somos pacientes ::to:: somos pacientes\n",
      " ::BLEU Score = 1.000000\n",
      "Compared:: ese no es mi problema ::to:: no es asunto mio\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: tom tiene dos opciones ::to:: tom tiene dos coches\n",
      " ::BLEU Score = 0.000000\n",
      "Compared:: me gusta la sopa de tomate ::to:: quisiera sopa de tom\n",
      " ::BLEU Score = 0.000000\n",
      "The Avaerage BLEU Score for the test set is: 0.132730\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "\n",
    "# Test sentences\n",
    "\n",
    "#print(\"Printing The first 10 Test Samples:\\n\")\n",
    "#for i in range(10):\n",
    "    #print('[' + Test_pairs[i, 0] + '] => [' + Test_pairs[i, 1] + ']')\n",
    "\n",
    "MyBleuScore = 0.0\n",
    "\n",
    "for i in range(TestSize):\n",
    "    weights=(0.25, 0.25, 0.25, 0.25)\n",
    "    reference = [Test_pairs[i, 1].split(' ')]\n",
    "    \n",
    "    #We do the translation here\n",
    "    translated_sentence = testThething(Test_pairs[i, 0])            \n",
    "    candidate = translated_sentence[0:-1].split(' ')#so we can drop the \\n\n",
    "    \n",
    "    #Borrowed section on dealing with short grams from https://github.com/nltk/nltk/issues/1554\n",
    "    if len(candidate)<4:\n",
    "        weights = ( 1 / (len(candidate)) ,) * (len(candidate))\n",
    "        LastBleuScore = sentence_bleu(reference, candidate,weights)\n",
    "    else:\n",
    "        LastBleuScore = sentence_bleu(reference, candidate)\n",
    "    \n",
    "    print(\"Compared::\",Test_pairs[i, 1], \"::to::\", translated_sentence, \"::BLEU Score = %f\" %LastBleuScore)\n",
    "    MyBleuScore += LastBleuScore\n",
    "\n",
    "MyBleuScore = MyBleuScore/TestSize\n",
    "\n",
    "print(\"The Avaerage BLEU Score for the test set is: %f\" %MyBleuScore )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
